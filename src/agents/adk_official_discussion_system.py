"""
ADKå®˜æ–¹å¤šæ™ºèƒ½ä½“è®¨è®ºç³»ç»Ÿ
ä¸¥æ ¼æŒ‰ç…§Google ADKå®˜æ–¹æ–‡æ¡£çš„æœ€ä½³å®è·µè®¾è®¡
https://google.github.io/adk-docs/agents/multi-agents/

å®ç°çš„ADKå®˜æ–¹æ¨¡å¼ï¼š
1. Parallel Fan-Out/Gather Pattern - å¹¶å‘æ‰§è¡Œå’Œç»“æœèšåˆ
2. Sequential Pipeline Pattern - é¡ºåºæµæ°´çº¿å¤„ç†
3. Iterative Refinement Pattern - è¿­ä»£ä¼˜åŒ–è¿‡ç¨‹
4. ä¸¥æ ¼ä½¿ç”¨ADKæ™ºèƒ½ä½“é™åˆ¶ï¼Œä¸åˆ›å»ºè™šæ‹Ÿæ™ºèƒ½ä½“
"""

import asyncio
import logging
from datetime import datetime
from typing import List, Dict, Any
from uuid import uuid4

from google.adk.agents import BaseAgent, LlmAgent, SequentialAgent, ParallelAgent, LoopAgent
from google.adk.agents.invocation_context import InvocationContext
from google.adk.events import Event, EventActions
from google.adk.models.lite_llm import LiteLlm
from google.genai import types

from src.utils.adk_session_manager import get_adk_session_manager

logger = logging.getLogger(__name__)

class ADKOfficialDiscussionSystem(LlmAgent):
    """
    ADKå®˜æ–¹å¤šæ™ºèƒ½ä½“è®¨è®ºç³»ç»Ÿ
    å®ç°å®˜æ–¹æ¨èçš„å¤šæ™ºèƒ½ä½“åä½œæ¨¡å¼

    ç»§æ‰¿LlmAgentä»¥æ”¯æŒç›´æ¥çš„å¤§æ¨¡å‹è®¿é—®å’Œé…ç½®
    """

    def __init__(self, model: str = "deepseek/deepseek-chat"):
        # ğŸ”§ ä¿®å¤ï¼šä½¿ç”¨é…ç½®æ–‡ä»¶ä¸­çš„APIå¯†é’¥é…ç½®LiteLLM
        from src.utils.config_manager import ConfigManager

        # è·å–LLMé…ç½®
        config_manager = ConfigManager()
        llm_config = config_manager.config.get('llm', {})  # ç›´æ¥è®¿é—®configä¸­çš„llmé…ç½®

        # ä½¿ç”¨é…ç½®æ–‡ä»¶ä¸­çš„å®Œæ•´LLMé…ç½®
        model_config = {
            'model': model,
            'api_key': llm_config.get('primary', {}).get('api_key'),
            'base_url': llm_config.get('primary', {}).get('base_url'),
            'max_tokens': llm_config.get('primary', {}).get('max_tokens', 4096),
            'temperature': llm_config.get('primary', {}).get('temperature', 0.7)
        }

        super().__init__(
            name="ADKOfficialDiscussionSystem",
            description="åŸºäºADKå®˜æ–¹æ ‡å‡†çš„å¤šæ™ºèƒ½ä½“è®¨è®ºç³»ç»Ÿï¼Œæ”¯æŒDeepSeekå¤§æ¨¡å‹",
            model=LiteLlm(**model_config),
            instruction="""
ä½ æ˜¯ADKå®˜æ–¹å¤šæ™ºèƒ½ä½“è®¨è®ºç³»ç»Ÿçš„åè°ƒå™¨ã€‚

ä½ çš„èŒè´£ï¼š
1. åè°ƒå¤šä¸ªå«æ˜Ÿæ™ºèƒ½ä½“çš„åä½œ
2. ç®¡ç†è®¨è®ºç»„çš„ç”Ÿå‘½å‘¨æœŸ
3. ç¡®ä¿ADKå®˜æ–¹æ¨¡å¼çš„æ­£ç¡®æ‰§è¡Œ
4. æä¾›ä¸“ä¸šçš„ä»»åŠ¡åˆ†æå’Œç»“æœèšåˆ

è¯·å§‹ç»ˆéµå¾ªADKå®˜æ–¹æœ€ä½³å®è·µï¼Œç¡®ä¿æ™ºèƒ½ä½“é—´çš„é«˜æ•ˆåä½œã€‚
"""
        )
        
        # æ´»è·ƒè®¨è®ºç»„
        self._active_discussions: Dict[str, BaseAgent] = {}
        
        # ç”Ÿå‘½å‘¨æœŸç›‘æ§
        self._lifecycle_monitor_task = None
        self._auto_cleanup_enabled = True
        self._max_discussion_lifetime = 600  # 10åˆ†é’Ÿæœ€å¤§ç”Ÿå‘½å‘¨æœŸ
        
        logger.info("âœ… ADKå®˜æ–¹è®¨è®ºç³»ç»Ÿåˆå§‹åŒ–å®Œæˆ")

        # å¯åŠ¨ç”Ÿå‘½å‘¨æœŸç›‘æ§
        self._ensure_lifecycle_monitoring()

    def _ensure_lifecycle_monitoring(self):
        """ç¡®ä¿ç”Ÿå‘½å‘¨æœŸç›‘æ§å·²å¯åŠ¨"""
        try:
            # æ£€æŸ¥æ˜¯å¦æœ‰è¿è¡Œçš„äº‹ä»¶å¾ªç¯
            loop = asyncio.get_running_loop()
            if self._lifecycle_monitor_task is None or self._lifecycle_monitor_task.done():
                self._lifecycle_monitor_task = loop.create_task(self._lifecycle_monitor())
                logger.info("âœ… ADKå®˜æ–¹è®¨è®ºç³»ç»Ÿç”Ÿå‘½å‘¨æœŸç›‘æ§å·²å¯åŠ¨")
        except RuntimeError:
            # æ²¡æœ‰è¿è¡Œçš„äº‹ä»¶å¾ªç¯ï¼ˆå¦‚åœ¨FlaskåŒæ­¥ç¯å¢ƒä¸­ï¼‰
            logger.info("âš ï¸ æ²¡æœ‰è¿è¡Œçš„äº‹ä»¶å¾ªç¯ï¼Œç”Ÿå‘½å‘¨æœŸç›‘æ§å°†åœ¨éœ€è¦æ—¶å¯åŠ¨")
            self._lifecycle_monitor_task = None

    async def start_lifecycle_monitoring_async(self):
        """åœ¨å¼‚æ­¥ç¯å¢ƒä¸­å¯åŠ¨ç”Ÿå‘½å‘¨æœŸç›‘æ§"""
        try:
            if self._lifecycle_monitor_task is None or self._lifecycle_monitor_task.done():
                self._lifecycle_monitor_task = asyncio.create_task(self._lifecycle_monitor())
                logger.info("âœ… ADKå®˜æ–¹è®¨è®ºç³»ç»Ÿç”Ÿå‘½å‘¨æœŸç›‘æ§å·²å¯åŠ¨ï¼ˆå¼‚æ­¥æ¨¡å¼ï¼‰")
                return True
            return False
        except Exception as e:
            logger.error(f"âŒ å¯åŠ¨ç”Ÿå‘½å‘¨æœŸç›‘æ§å¤±è´¥: {e}")
            return False

    async def _lifecycle_monitor(self):
        """ç”Ÿå‘½å‘¨æœŸç›‘æ§ä»»åŠ¡"""
        try:
            while self._auto_cleanup_enabled:
                await asyncio.sleep(60)  # æ¯åˆ†é’Ÿæ£€æŸ¥ä¸€æ¬¡
                await self._cleanup_expired_discussions()
        except asyncio.CancelledError:
            logger.info("ğŸ›‘ ç”Ÿå‘½å‘¨æœŸç›‘æ§å·²åœæ­¢")
        except Exception as e:
            logger.error(f"âŒ ç”Ÿå‘½å‘¨æœŸç›‘æ§å¼‚å¸¸: {e}")

    async def _cleanup_expired_discussions(self):
        """æ¸…ç†è¿‡æœŸçš„è®¨è®ºç»„"""
        try:
            current_time = datetime.now()
            expired_discussions = []
            
            for discussion_id, discussion_agent in self._active_discussions.items():
                creation_time = getattr(discussion_agent, '_creation_time', current_time)
                if (current_time - creation_time).total_seconds() > self._max_discussion_lifetime:
                    expired_discussions.append(discussion_id)
            
            for discussion_id in expired_discussions:
                await self.complete_discussion(discussion_id)
                logger.info(f"ğŸ§¹ å·²æ¸…ç†è¿‡æœŸè®¨è®ºç»„: {discussion_id}")
                
        except Exception as e:
            logger.error(f"âŒ æ¸…ç†è¿‡æœŸè®¨è®ºç»„å¤±è´¥: {e}")

    async def create_discussion_with_adk_patterns(
        self,
        pattern_type: str,
        participating_agents: List[BaseAgent],
        task_description: str
    ) -> str:
        """
        ä½¿ç”¨ADKå®˜æ–¹å¤šæ™ºèƒ½ä½“æ¨¡å¼åˆ›å»ºè®¨è®ºç»„
        ä¸¥æ ¼æŒ‰ç…§ADKå®˜æ–¹æ–‡æ¡£çš„Parallel Fan-Out/Gather Patternè®¾è®¡

        Args:
            pattern_type: åä½œæ¨¡å¼ ("parallel_fanout", "sequential_pipeline", "iterative_refinement")
            participating_agents: å‚ä¸è®¨è®ºçš„å…·èº«å«æ˜Ÿæ™ºèƒ½ä½“åˆ—è¡¨
            task_description: ä»»åŠ¡æè¿°

        Returns:
            è®¨è®ºID
        """
        try:
            from google.adk.agents import ParallelAgent, SequentialAgent, LlmAgent

            logger.info(f"ğŸ”„ ä½¿ç”¨ADKå®˜æ–¹æ¨¡å¼åˆ›å»ºè®¨è®ºç»„: {pattern_type}")
            logger.info(f"   å‚ä¸æ™ºèƒ½ä½“: {[agent.name for agent in participating_agents]}")
            logger.info(f"   ä»»åŠ¡æè¿°: {task_description}")

            # ç¡®ä¿ç”Ÿå‘½å‘¨æœŸç›‘æ§å·²å¯åŠ¨
            self._ensure_lifecycle_monitoring()

            # å¦‚æœåœ¨å¼‚æ­¥ç¯å¢ƒä¸­ï¼Œå°è¯•å¯åŠ¨å¼‚æ­¥ç”Ÿå‘½å‘¨æœŸç›‘æ§
            if self._lifecycle_monitor_task is None:
                await self.start_lifecycle_monitoring_async()

            # æ£€æŸ¥å¹¶æ¸…ç†æ™ºèƒ½ä½“çš„æ—§å…³ç³»
            await self._cleanup_agents_old_relationships(participating_agents)

            # å¼ºåˆ¶é‡ç½®æ™ºèƒ½ä½“çŠ¶æ€
            await self._force_reset_agents(participating_agents)

            # ç”Ÿæˆè®¨è®ºç»„ID
            discussion_id = f"adk_official_{uuid4().hex[:8]}"

            # éªŒè¯å‚ä¸æ™ºèƒ½ä½“éƒ½æ˜¯å…·èº«å«æ˜Ÿæ™ºèƒ½ä½“
            for agent in participating_agents:
                if not hasattr(agent, 'satellite_id'):
                    raise ValueError(f"æ™ºèƒ½ä½“ {agent.name} ä¸æ˜¯å…·èº«å«æ˜Ÿæ™ºèƒ½ä½“")

            # # æŒ‰ç…§ADKå®˜æ–¹æ¨¡å¼åˆ›å»ºè®¨è®ºç»„æ™ºèƒ½ä½“
            # if pattern_type == "parallel_fanout":
            #     # Parallel Fan-Out/Gather Pattern - ADKå®˜æ–¹æ¨èæ¨¡å¼
            #     discussion_agent = self._create_adk_parallel_fanout_pattern(
            #         discussion_id, participating_agents, task_description
            #     )
            # elif pattern_type == "sequential_pipeline":
            #     # Sequential Pipeline Pattern - ADKå®˜æ–¹æ¨èæ¨¡å¼
            #     discussion_agent = self._create_adk_sequential_pipeline_pattern(
            #         discussion_id, participating_agents, task_description
            #     )
            # elif pattern_type == "iterative_refinement":
            #     # Iterative Refinement Pattern - ADKå®˜æ–¹æ¨èæ¨¡å¼
            #     discussion_agent = self._create_adk_iterative_refinement_pattern(
            #         discussion_id, participating_agents, task_description
            #     )
            # else:
            #     raise ValueError(f"ä¸æ”¯æŒçš„åä½œæ¨¡å¼: {pattern_type}")

            # Iterative Refinement Pattern - ADKå®˜æ–¹æ¨èæ¨¡å¼
            discussion_agent = self._create_adk_iterative_refinement_pattern(
                discussion_id, participating_agents, task_description
            )

            # è®¾ç½®åˆ›å»ºæ—¶é—´
            discussion_agent._creation_time = datetime.now()

            # æ³¨å†Œè®¨è®ºç»„
            self._active_discussions[discussion_id] = discussion_agent

            # æ³¨å†Œåˆ°ADK Sessionç®¡ç†å™¨
            session_manager = get_adk_session_manager()
            discussion_info = {
                'discussion_id': discussion_id,
                'pattern_type': pattern_type,
                'agent_count': len(participating_agents),
                'task_description': task_description,
                'creation_time': datetime.now().isoformat()
            }
            session_manager.add_adk_discussion(discussion_id, discussion_info)

            logger.info(f"âœ… ADKå®˜æ–¹æ¨¡å¼è®¨è®ºç»„åˆ›å»ºæˆåŠŸ: {discussion_id} (æ¨¡å¼: {pattern_type})")
            logger.info(f"   è®¨è®ºç»„ç±»å‹: {discussion_agent.__class__.__name__}")
            logger.info(f"   ä½¿ç”¨ADKåŸç”ŸInvocationContextï¼Œè‡ªåŠ¨æ”¯æŒmodel_copy")

            # ğŸ”§ ä¿®å¤ï¼šç«‹å³æ‰§è¡Œè®¨è®ºç»„è¿›è¡ŒLLMæ¨ç†
            await self._execute_discussion_group(discussion_id, discussion_agent, task_description)

            return discussion_id

        except Exception as e:
            logger.error(f"âŒ ä½¿ç”¨ADKå®˜æ–¹æ¨¡å¼åˆ›å»ºè®¨è®ºç»„å¤±è´¥: {e}")
            raise

    async def create_discussion(
        self,
        pattern_type: str,
        participating_agents: List[BaseAgent],
        task_description: str,
        ctx=None
    ) -> str:
        """
        åˆ›å»ºADKå®˜æ–¹å¤šæ™ºèƒ½ä½“è®¨è®ºç»„ï¼ˆå‘åå…¼å®¹æ–¹æ³•ï¼‰

        è¿™ä¸ªæ–¹æ³•ä¿æŒå‘åå…¼å®¹ï¼Œä½†å†…éƒ¨ä½¿ç”¨æ–°çš„Runneræ–¹å¼

        Args:
            pattern_type: åä½œæ¨¡å¼
            participating_agents: å‚ä¸è®¨è®ºçš„å…·èº«å«æ˜Ÿæ™ºèƒ½ä½“åˆ—è¡¨
            task_description: ä»»åŠ¡æè¿°
            ctx: ä¸Šä¸‹æ–‡ï¼ˆå°†è¢«å¿½ç•¥ï¼Œä½¿ç”¨Runnerè‡ªåŠ¨åˆ›å»ºï¼‰

        Returns:
            è®¨è®ºID
        """
        logger.info(f"ğŸ”„ åˆ›å»ºADKè®¨è®ºç»„ï¼ˆå…¼å®¹æ¨¡å¼ï¼‰: {pattern_type}")

        # å†…éƒ¨è°ƒç”¨æ–°çš„ADKå®˜æ–¹æ¨¡å¼
        return await self.create_discussion_with_adk_patterns(
            pattern_type=pattern_type,
            participating_agents=participating_agents,
            task_description=task_description
        )

    async def _execute_discussion_group(self, discussion_id: str, discussion_agent, task_description: str):
        """
        æ‰§è¡Œè®¨è®ºç»„è¿›è¡Œå®é™…çš„LLMæ¨ç†

        ä½¿ç”¨ADKå®˜æ–¹æ¨èçš„InMemoryRunnerå’Œæ­£ç¡®çš„API
        """
        try:
            logger.info(f"ğŸš€ å¼€å§‹æ‰§è¡Œè®¨è®ºç»„: {discussion_id}")
            logger.info(f"   æ™ºèƒ½ä½“ç±»å‹: {discussion_agent.__class__.__name__}")
            logger.info(f"   ä»»åŠ¡: {task_description}")

            # ğŸ”§ ä¿®å¤ï¼šä½¿ç”¨ADKå®˜æ–¹æ–‡æ¡£çš„æ­£ç¡®æ–¹å¼
            from google.adk.runners import Runner
            from google.adk.sessions import InMemorySessionService
            from google.genai import types

            # åˆ›å»ºä¼šè¯æœåŠ¡
            session_service = InMemorySessionService()

            # åˆ›å»ºä¼šè¯
            app_name = "adk_discussion_system"
            user_id = "system"
            session_id = f"discussion_{discussion_id}"

            session = await session_service.create_session(
                app_name=app_name,
                user_id=user_id,
                session_id=session_id
            )

            # åˆ›å»ºRunner
            runner = Runner(
                agent=discussion_agent,
                app_name=app_name,
                session_service=session_service
            )

            logger.info(f"ğŸ§  å¼€å§‹LLMæ¨ç†...")

            # æ„å»ºç”¨æˆ·æ¶ˆæ¯å†…å®¹
            user_message_content = types.Content(
                role='user',
                parts=[types.Part(text=f"""
ä»»åŠ¡æè¿°: {task_description}

è¯·è¿›è¡Œä¸“ä¸šåˆ†æï¼ŒåŒ…æ‹¬ï¼š
1. GDOPè®¡ç®—å’Œè¯„ä¼°ï¼ˆGDOPå€¼è¶Šå°è¶Šå¥½ï¼Œç†æƒ³å€¼<2.0ï¼‰
2. é²æ£’æ€§åˆ†æï¼ˆè¯„åˆ†0-100ï¼‰
3. è¦†ç›–ç‡è¯„ä¼°ï¼ˆç™¾åˆ†æ¯”ï¼‰
4. ä»»åŠ¡å¯è¡Œæ€§åˆ†æ

è¯·æä¾›å…·ä½“çš„æ•°å€¼æŒ‡æ ‡å’Œä¸“ä¸šå»ºè®®ã€‚
""")]
            )

            # ğŸ”§ ä¿®å¤ï¼šä½¿ç”¨æ­£ç¡®çš„run_async API
            response_events = []
            async for event in runner.run_async(
                user_id=user_id,
                session_id=session_id,
                new_message=user_message_content
            ):
                response_events.append(event)

                # åŸºç¡€äº‹ä»¶æ—¥å¿—
                logger.info(f"ğŸ“ æ”¶åˆ°äº‹ä»¶: {event.author} - {len(str(event.content)) if event.content else 0} å­—ç¬¦")

                # ğŸ”§ æ–°å¢ï¼šè¯¦ç»†çš„è¿­ä»£æŒ‡æ ‡æ—¥å¿—è¾“å‡º
                if event.author and "QualityChecker" in event.author:
                    # è¿™æ˜¯è´¨é‡æ£€æŸ¥å™¨çš„å“åº”ï¼ŒåŒ…å«è¿­ä»£æŒ‡æ ‡
                    if event.content and event.content.parts:
                        quality_response = ""
                        for part in event.content.parts:
                            if hasattr(part, 'text') and part.text:
                                quality_response += part.text

                        if quality_response:
                            logger.info(f"ğŸ“Š è´¨é‡æ£€æŸ¥å™¨è¿­ä»£æŒ‡æ ‡åˆ†æ:")

                            # æå–å…³é”®æŒ‡æ ‡
                            lines = quality_response.split('\n')
                            for line in lines:
                                line = line.strip()
                                if any(keyword in line for keyword in ['GDOPè¯„åˆ†', 'GDOPåˆ†æ•°', 'gdop', 'GDOP']):
                                    logger.info(f"   ğŸ¯ {line}")
                                elif any(keyword in line for keyword in ['é²æ£’æ€§è¯„åˆ†', 'é²æ£’æ€§åˆ†æ•°', 'é²æ£’æ€§']):
                                    logger.info(f"   ğŸ›¡ï¸ {line}")
                                elif any(keyword in line for keyword in ['è¦†ç›–ç‡è¯„åˆ†', 'è¦†ç›–ç‡åˆ†æ•°', 'è¦†ç›–ç‡']):
                                    logger.info(f"   ğŸ“¡ {line}")
                                elif any(keyword in line for keyword in ['æ•ˆç‡è¯„åˆ†', 'æ•ˆç‡åˆ†æ•°', 'æ•ˆç‡']):
                                    logger.info(f"   âš¡ {line}")
                                elif any(keyword in line for keyword in ['ç»¼åˆè´¨é‡åˆ†æ•°', 'ç»¼åˆåˆ†æ•°', 'æ€»åˆ†']):
                                    logger.info(f"   ğŸ† {line}")
                                elif any(keyword in line for keyword in ['æ˜¯å¦ç»§ç»­è¿­ä»£', 'è¿­ä»£å†³ç­–', 'ç»§ç»­è¿­ä»£']):
                                    logger.info(f"   ğŸ”„ {line}")
                                elif any(keyword in line for keyword in ['å†³ç­–ç†ç”±', 'ç†ç”±']):
                                    logger.info(f"   ğŸ’­ {line}")

                            # æ˜¾ç¤ºå®Œæ•´å“åº”çš„å‰å‡ è¡Œ
                            logger.info(f"ğŸ“‹ è´¨é‡æ£€æŸ¥å™¨å®Œæ•´å“åº”æ‘˜è¦:")
                            response_lines = quality_response.split('\n')[:8]
                            for i, line in enumerate(response_lines):
                                if line.strip():
                                    logger.info(f"   {i+1}. {line.strip()}")

                            if len(response_lines) > 8:
                                logger.info(f"   ... (è¿˜æœ‰ {len(quality_response.split('\n')) - 8} è¡Œ)")

                # ğŸ”§ æ–°å¢ï¼šå«æ˜Ÿæ™ºèƒ½ä½“è¯¦ç»†å“åº”æ—¥å¿—
                elif event.author and any(sat_name in event.author for sat_name in ['Satellite', 'GDOP_Sat', 'TestSat']):
                    if event.content and event.content.parts:
                        satellite_response = ""
                        for part in event.content.parts:
                            if hasattr(part, 'text') and part.text:
                                satellite_response += part.text

                        if satellite_response and len(satellite_response) > 50:  # é™ä½é˜ˆå€¼ï¼Œæ˜¾ç¤ºæ›´å¤šå“åº”
                            logger.info(f"ğŸ›°ï¸ å«æ˜Ÿæ™ºèƒ½ä½“ {event.author} LLMå“åº”åˆ†æ:")

                            # æå–å…³é”®ä¿¡æ¯
                            lines = satellite_response.split('\n')
                            for line in lines:
                                line = line.strip()
                                if any(keyword in line.lower() for keyword in ['gdop', 'å‡ ä½•ç²¾åº¦', 'å®šä½ç²¾åº¦']):
                                    logger.info(f"   ğŸ¯ GDOPç›¸å…³: {line}")
                                elif any(keyword in line.lower() for keyword in ['ä»»åŠ¡', 'task', 'æ‰§è¡Œ', 'çŠ¶æ€']):
                                    logger.info(f"   ğŸ“‹ ä»»åŠ¡çŠ¶æ€: {line}")
                                elif any(keyword in line.lower() for keyword in ['èµ„æº', 'resource', 'åŠŸç‡', 'ç‡ƒæ–™']):
                                    logger.info(f"   âš¡ èµ„æºçŠ¶æ€: {line}")
                                elif any(keyword in line.lower() for keyword in ['è¦†ç›–', 'coverage', 'å¯è§', 'è§‚æµ‹']):
                                    logger.info(f"   ğŸ“¡ è¦†ç›–åˆ†æ: {line}")
                                elif any(keyword in line.lower() for keyword in ['è½¨é“', 'orbit', 'ä½ç½®', 'position']):
                                    logger.info(f"   ğŸŒ è½¨é“ä¿¡æ¯: {line}")
                                elif any(keyword in line.lower() for keyword in ['åˆ†æ', 'analysis', 'è¯„ä¼°', 'è®¡ç®—']):
                                    logger.info(f"   ğŸ“Š åˆ†æç»“æœ: {line}")

                            # æ˜¾ç¤ºå®Œæ•´å“åº”æ‘˜è¦
                            logger.info(f"ğŸ“‹ å«æ˜Ÿæ™ºèƒ½ä½“ {event.author} å®Œæ•´å“åº”æ‘˜è¦:")
                            response_lines = satellite_response.split('\n')[:6]
                            for i, line in enumerate(response_lines):
                                if line.strip():
                                    logger.info(f"   {i+1}. {line.strip()}")

                            if len(response_lines) > 6:
                                logger.info(f"   ... (è¿˜æœ‰ {len(satellite_response.split('\n')) - 6} è¡Œï¼Œå…± {len(satellite_response)} å­—ç¬¦)")

                # ğŸ”§ æ–°å¢ï¼šèšåˆå™¨æ™ºèƒ½ä½“è¯¦ç»†å“åº”æ—¥å¿—
                elif event.author and any(agent_name in event.author for agent_name in ['GatherAgent', 'Gather', 'Aggregator']):
                    if event.content and event.content.parts:
                        gather_response = ""
                        for part in event.content.parts:
                            if hasattr(part, 'text') and part.text:
                                gather_response += part.text

                        if gather_response:
                            logger.info(f"ğŸ”„ èšåˆå™¨æ™ºèƒ½ä½“ {event.author} LLMå“åº”åˆ†æ:")

                            # æå–å…³é”®èšåˆä¿¡æ¯
                            lines = gather_response.split('\n')
                            for line in lines:
                                line = line.strip()
                                if any(keyword in line.lower() for keyword in ['ç»¼åˆ', 'èšåˆ', 'æ•´åˆ', 'æ±‡æ€»']):
                                    logger.info(f"   ğŸ”„ èšåˆåˆ†æ: {line}")
                                elif any(keyword in line.lower() for keyword in ['gdop', 'å‡ ä½•ç²¾åº¦']):
                                    logger.info(f"   ğŸ¯ GDOPèšåˆ: {line}")
                                elif any(keyword in line.lower() for keyword in ['å»ºè®®', 'recommend', 'ä¼˜åŒ–', 'æ”¹è¿›']):
                                    logger.info(f"   ğŸ’¡ ä¼˜åŒ–å»ºè®®: {line}")
                                elif any(keyword in line.lower() for keyword in ['ç»“è®º', 'conclusion', 'æ€»ç»“', 'è¯„ä¼°']):
                                    logger.info(f"   ğŸ“Š è¯„ä¼°ç»“è®º: {line}")

                            # æ˜¾ç¤ºèšåˆå™¨å®Œæ•´å“åº”æ‘˜è¦
                            logger.info(f"ğŸ“‹ èšåˆå™¨ {event.author} å®Œæ•´å“åº”æ‘˜è¦:")
                            response_lines = gather_response.split('\n')[:8]
                            for i, line in enumerate(response_lines):
                                if line.strip():
                                    logger.info(f"   {i+1}. {line.strip()}")

                            if len(response_lines) > 8:
                                logger.info(f"   ... (è¿˜æœ‰ {len(gather_response.split('\n')) - 8} è¡Œï¼Œå…± {len(gather_response)} å­—ç¬¦)")

                # ğŸ”§ æ–°å¢ï¼šå…¶ä»–æ™ºèƒ½ä½“è¯¦ç»†å“åº”æ—¥å¿—
                elif event.author and event.content and event.content.parts:
                    # å¤„ç†å…¶ä»–ç±»å‹çš„æ™ºèƒ½ä½“å“åº”
                    other_response = ""
                    for part in event.content.parts:
                        if hasattr(part, 'text') and part.text:
                            other_response += part.text

                    if other_response and len(other_response) > 100:
                        logger.info(f"ğŸ¤– æ™ºèƒ½ä½“ {event.author} LLMå“åº”åˆ†æ:")

                        # æå–é€šç”¨å…³é”®ä¿¡æ¯
                        lines = other_response.split('\n')
                        key_lines = []
                        for line in lines:
                            line = line.strip()
                            if any(keyword in line.lower() for keyword in ['gdop', 'åˆ†æ', 'analysis', 'è¯„ä¼°', 'ç»“æœ', 'å»ºè®®']):
                                key_lines.append(line)

                        # æ˜¾ç¤ºå…³é”®ä¿¡æ¯
                        for line in key_lines[:5]:  # æœ€å¤šæ˜¾ç¤º5è¡Œå…³é”®ä¿¡æ¯
                            logger.info(f"   ğŸ“ {line}")

                        # æ˜¾ç¤ºå“åº”æ‘˜è¦
                        logger.info(f"ğŸ“‹ æ™ºèƒ½ä½“ {event.author} å“åº”æ‘˜è¦:")
                        response_lines = other_response.split('\n')[:4]
                        for i, line in enumerate(response_lines):
                            if line.strip():
                                logger.info(f"   {i+1}. {line.strip()}")

                        if len(response_lines) > 4:
                            logger.info(f"   ... (å…± {len(other_response)} å­—ç¬¦)")

            # åˆå¹¶æ‰€æœ‰å“åº”
            response = ""
            for event in response_events:
                if event.content and hasattr(event.content, 'parts'):
                    for part in event.content.parts:
                        if hasattr(part, 'text') and part.text:
                            response += part.text

            # ğŸ”§ æ–°å¢ï¼šLLMå“åº”ç»Ÿè®¡åˆ†æ
            logger.info(f"ğŸ§  LLMæ¨ç†å®Œæˆï¼Œå“åº”é•¿åº¦: {len(str(response))} å­—ç¬¦")

            # ç»Ÿè®¡å„ç±»æ™ºèƒ½ä½“çš„å“åº”
            agent_responses = {}
            total_response_length = 0

            for event in response_events:
                if event.author and event.content and event.content.parts:
                    event_response = ""
                    for part in event.content.parts:
                        if hasattr(part, 'text') and part.text:
                            event_response += part.text

                    if event_response:
                        agent_type = "å…¶ä»–æ™ºèƒ½ä½“"
                        if "QualityChecker" in event.author:
                            agent_type = "è´¨é‡æ£€æŸ¥å™¨"
                        elif any(sat_name in event.author for sat_name in ['Satellite', 'GDOP_Sat', 'TestSat']):
                            agent_type = "å«æ˜Ÿæ™ºèƒ½ä½“"
                        elif any(agent_name in event.author for agent_name in ['GatherAgent', 'Gather', 'Aggregator']):
                            agent_type = "èšåˆå™¨æ™ºèƒ½ä½“"

                        if agent_type not in agent_responses:
                            agent_responses[agent_type] = []
                        agent_responses[agent_type].append({
                            'author': event.author,
                            'length': len(event_response),
                            'content': event_response[:100] + "..." if len(event_response) > 100 else event_response
                        })
                        total_response_length += len(event_response)

            # æ˜¾ç¤ºå“åº”ç»Ÿè®¡
            logger.info(f"ğŸ“Š LLMå“åº”ç»Ÿè®¡åˆ†æ:")
            logger.info(f"   æ€»å“åº”é•¿åº¦: {total_response_length} å­—ç¬¦")
            logger.info(f"   å‚ä¸æ™ºèƒ½ä½“ç±»å‹: {len(agent_responses)} ç§")
            logger.info(f"   æ€»å“åº”äº‹ä»¶æ•°: {len([e for e in response_events if e.content])} ä¸ª")

            for agent_type, responses in agent_responses.items():
                total_length = sum(r['length'] for r in responses)
                logger.info(f"   ğŸ“‹ {agent_type}: {len(responses)} ä¸ªå“åº”ï¼Œå…± {total_length} å­—ç¬¦")
                for resp in responses:
                    logger.info(f"      - {resp['author']}: {resp['length']} å­—ç¬¦")

            logger.info(f"ğŸ“Š LLMå“åº”æ‘˜è¦: {str(response)[:200]}...")

            # ğŸ”§ æ–°å¢ï¼šè¿­ä»£è¿›åº¦ç»Ÿè®¡
            quality_checker_events = [e for e in response_events if e.author and "QualityChecker" in e.author]
            if quality_checker_events:
                current_iteration = len(quality_checker_events)
                logger.info(f"ğŸ”„ è¿­ä»£è¿›åº¦ç»Ÿè®¡:")
                logger.info(f"   å½“å‰è¿­ä»£æ¬¡æ•°: {current_iteration}")
                logger.info(f"   æœ€å¤§è¿­ä»£æ¬¡æ•°: 5")
                logger.info(f"   è¿­ä»£è¿›åº¦: {current_iteration}/5 ({current_iteration/5*100:.1f}%)")

                # åˆ†æè¿­ä»£è¶‹åŠ¿
                if current_iteration > 1:
                    logger.info(f"   è¿­ä»£çŠ¶æ€: æ­£åœ¨è¿›è¡Œå¤šè½®ä¼˜åŒ–")
                elif current_iteration == 1:
                    logger.info(f"   è¿­ä»£çŠ¶æ€: é¦–æ¬¡è´¨é‡æ£€æŸ¥å®Œæˆ")

                # æ£€æŸ¥æ˜¯å¦åº”è¯¥åœæ­¢è¿­ä»£
                last_quality_event = quality_checker_events[-1]
                if last_quality_event.content and last_quality_event.content.parts:
                    last_response = ""
                    for part in last_quality_event.content.parts:
                        if hasattr(part, 'text') and part.text:
                            last_response += part.text

                    if "åœæ­¢è¿­ä»£" in last_response or "ä¸ç»§ç»­" in last_response or "escalate" in last_response.lower():
                        logger.info(f"   ğŸ›‘ è´¨é‡æ£€æŸ¥å™¨å»ºè®®åœæ­¢è¿­ä»£")
                    elif "ç»§ç»­è¿­ä»£" in last_response or "éœ€è¦ä¼˜åŒ–" in last_response:
                        logger.info(f"   â­ï¸ è´¨é‡æ£€æŸ¥å™¨å»ºè®®ç»§ç»­è¿­ä»£")
            else:
                logger.info(f"ğŸ”„ è¿­ä»£æ¨¡å¼: éè¿­ä»£ä¼˜åŒ–æ¨¡å¼æˆ–é¦–æ¬¡æ‰§è¡Œ")

            # ä¿å­˜æ‰§è¡Œç»“æœåˆ°è®¨è®ºç»„
            if not hasattr(discussion_agent, '_execution_results'):
                discussion_agent._execution_results = {}

            discussion_agent._execution_results[discussion_id] = {
                'response': str(response),
                'execution_time': datetime.now().isoformat(),
                'task_description': task_description,
                'status': 'completed',
                'session_id': session_id
            }

            logger.info(f"âœ… è®¨è®ºç»„æ‰§è¡Œå®Œæˆ: {discussion_id}")

        except Exception as e:
            logger.error(f"âŒ æ‰§è¡Œè®¨è®ºç»„å¤±è´¥: {discussion_id}, é”™è¯¯: {e}")
            import traceback
            traceback.print_exc()

            # ä¿å­˜é”™è¯¯ä¿¡æ¯
            if not hasattr(discussion_agent, '_execution_results'):
                discussion_agent._execution_results = {}

            discussion_agent._execution_results[discussion_id] = {
                'error': str(e),
                'execution_time': datetime.now().isoformat(),
                'task_description': task_description,
                'status': 'failed'
            }

            # ä¸æŠ›å‡ºå¼‚å¸¸ï¼Œè®©è®¨è®ºç»„åˆ›å»ºæˆåŠŸï¼Œä½†æ ‡è®°ä¸ºæ‰§è¡Œå¤±è´¥

    async def _cleanup_agents_old_relationships(self, agents: List[BaseAgent]):
        """æ£€æŸ¥å¹¶æ¸…ç†æ™ºèƒ½ä½“çš„æ—§å…³ç³»"""
        logger.info(f"ğŸ§¹ æ£€æŸ¥å¹¶æ¸…ç† {len(agents)} ä¸ªæ™ºèƒ½ä½“çš„æ—§å…³ç³»")
        
        for agent in agents:
            # æ£€æŸ¥æ˜¯å¦æœ‰æ—§çš„çˆ¶å­å…³ç³»
            if hasattr(agent, '_parent_agent'):
                delattr(agent, '_parent_agent')
            if hasattr(agent, '_sub_agents'):
                delattr(agent, '_sub_agents')
            if hasattr(agent, '_discussion_id'):
                delattr(agent, '_discussion_id')
        
        logger.info("âœ… æ‰€æœ‰æ™ºèƒ½ä½“éƒ½æ²¡æœ‰æ—§çš„çˆ¶å­å…³ç³»")

    async def _force_reset_agents(self, agents: List[BaseAgent]):
        """å¼ºåˆ¶é‡ç½®æ™ºèƒ½ä½“çŠ¶æ€"""
        logger.info(f"ğŸ”§ å¼ºåˆ¶é‡ç½® {len(agents)} ä¸ªæ™ºèƒ½ä½“çŠ¶æ€")
        
        for agent in agents:
            # é‡ç½®æ™ºèƒ½ä½“çš„å†…éƒ¨çŠ¶æ€
            if hasattr(agent, '_last_response'):
                agent._last_response = None
            if hasattr(agent, '_execution_count'):
                agent._execution_count = 0
        
        logger.info("âœ… æ‰€æœ‰æ™ºèƒ½ä½“çŠ¶æ€é‡ç½®å®Œæˆ")

    async def complete_discussion(self, discussion_id: str) -> Dict[str, Any]:
        """
        å®Œæˆå¹¶è§£æ•£è®¨è®ºç»„ï¼ˆADKæ ‡å‡†æ–¹å¼ï¼‰

        æŒ‰ç…§ADKå®˜æ–¹æ–‡æ¡£ï¼Œæ­£ç¡®è§£æ•£æ™ºèƒ½ä½“ä½†ä¿æŒå…·èº«æ™ºèƒ½ä½“çŠ¶æ€

        Returns:
            åŒ…å«æ‰§è¡Œç»“æœçš„å­—å…¸
        """
        try:
            if discussion_id in self._active_discussions:
                discussion_agent = self._active_discussions[discussion_id]

                # è·å–æ‰§è¡Œç»“æœ
                execution_results = getattr(discussion_agent, '_execution_results', {})
                discussion_result = execution_results.get(discussion_id, {})

                # åˆ†ææ‰§è¡Œç»“æœ
                if discussion_result.get('status') == 'completed':
                    status = 'success'
                    response = discussion_result.get('response', '')

                    # ç®€å•çš„è´¨é‡è¯„ä¼°ï¼ˆåŸºäºå“åº”é•¿åº¦å’Œå…³é”®è¯ï¼‰
                    quality_score = self._evaluate_response_quality(response)

                    logger.info(f"ï¿½ è®¨è®ºç»„æ‰§è¡ŒæˆåŠŸ: {discussion_id}")
                    logger.info(f"   å“åº”é•¿åº¦: {len(response)} å­—ç¬¦")
                    logger.info(f"   è´¨é‡è¯„åˆ†: {quality_score:.3f}")

                elif discussion_result.get('status') == 'failed':
                    status = 'failed'
                    quality_score = 0.0
                    response = f"æ‰§è¡Œå¤±è´¥: {discussion_result.get('error', 'æœªçŸ¥é”™è¯¯')}"

                    logger.error(f"âŒ è®¨è®ºç»„æ‰§è¡Œå¤±è´¥: {discussion_id}")
                    logger.error(f"   é”™è¯¯: {discussion_result.get('error', 'æœªçŸ¥é”™è¯¯')}")

                else:
                    status = 'failed'
                    quality_score = 0.0
                    response = "æœªæ‰¾åˆ°æ‰§è¡Œç»“æœ"

                    logger.warning(f"âš ï¸ è®¨è®ºç»„æ— æ‰§è¡Œç»“æœ: {discussion_id}")

                # ï¿½ğŸ”§ ADKæ ‡å‡†ï¼šå®‰å…¨è§£æ•£æ™ºèƒ½ä½“ï¼Œä¿æŒå…·èº«æ™ºèƒ½ä½“çŠ¶æ€
                await self._dissolve_discussion_agents_safely(discussion_agent)

                # æ¸…ç†è®¨è®ºç»„å¼•ç”¨
                del self._active_discussions[discussion_id]

                # ä»Sessionç®¡ç†å™¨ä¸­ç§»é™¤
                session_manager = get_adk_session_manager()
                session_manager.remove_adk_discussion(discussion_id)

                logger.info(f"âœ… è®¨è®ºç»„å·²å®‰å…¨è§£æ•£: {discussion_id}")
                logger.info(f"   å…·èº«æ™ºèƒ½ä½“çŠ¶æ€å·²ä¿æŒï¼Œå¯ç”¨äºä¸‹æ¬¡æ»šåŠ¨è§„åˆ’")

                return {
                    'success': True,
                    'status': status,
                    'quality_score': quality_score,
                    'response': response,
                    'execution_time': discussion_result.get('execution_time'),
                    'iterations': 1  # å½“å‰å®ç°ä¸ºå•æ¬¡æ‰§è¡Œ
                }
            else:
                logger.warning(f"âš ï¸ è®¨è®ºç»„ä¸å­˜åœ¨: {discussion_id}")
                return {
                    'success': False,
                    'status': 'failed',
                    'quality_score': 0.0,
                    'response': f"è®¨è®ºç»„ä¸å­˜åœ¨: {discussion_id}",
                    'iterations': 0
                }

        except Exception as e:
            logger.error(f"âŒ è§£æ•£è®¨è®ºç»„å¤±è´¥: {e}")
            return {
                'success': False,
                'status': 'failed',
                'quality_score': 0.0,
                'response': f"è§£æ•£å¤±è´¥: {e}",
                'iterations': 0
            }

    def _evaluate_response_quality(self, response: str) -> float:
        """
        è¯„ä¼°å“åº”è´¨é‡

        ç®€å•çš„è´¨é‡è¯„ä¼°ç®—æ³•ï¼ŒåŸºäºå“åº”é•¿åº¦å’Œå…³é”®è¯
        """
        if not response:
            return 0.0

        # åŸºç¡€åˆ†æ•°ï¼ˆåŸºäºé•¿åº¦ï¼‰
        length_score = min(len(response) / 1000.0, 0.5)  # æœ€å¤š0.5åˆ†

        # å…³é”®è¯åˆ†æ•°
        keywords = ['gdop', 'GDOP', 'é²æ£’æ€§', 'è¦†ç›–ç‡', 'å¯è¡Œæ€§', 'åˆ†æ', 'è¯„ä¼°', 'è®¡ç®—']
        keyword_score = 0.0
        for keyword in keywords:
            if keyword in response:
                keyword_score += 0.1

        keyword_score = min(keyword_score, 0.5)  # æœ€å¤š0.5åˆ†

        total_score = length_score + keyword_score
        return min(total_score, 1.0)  # æœ€é«˜1.0åˆ†

    async def _dissolve_discussion_agents_safely(self, discussion_agent):
        """
        å®‰å…¨è§£æ•£è®¨è®ºç»„ä¸­çš„æ™ºèƒ½ä½“ï¼ˆADKæ ‡å‡†æ–¹å¼ï¼‰

        æ ¹æ®ADKå®˜æ–¹æ–‡æ¡£ï¼š
        1. åªæ¸…ç†çˆ¶å­å…³ç³»ï¼Œä¸é‡æ–°åˆå§‹åŒ–å…·èº«æ™ºèƒ½ä½“
        2. ä¿æŒå…·èº«æ™ºèƒ½ä½“çš„ä»»åŠ¡çŠ¶æ€å’Œèµ„æºçŠ¶æ€
        3. ç¡®ä¿ä¸‹æ¬¡æ»šåŠ¨è§„åˆ’å¯ä»¥æ­£ç¡®ä½¿ç”¨è¿™äº›çŠ¶æ€
        """
        try:
            # è·å–è®¨è®ºç»„ä¸­çš„å‚ä¸æ™ºèƒ½ä½“
            participating_agents = getattr(discussion_agent, '_discussion_members', [])

            logger.info(f"ğŸ”„ å¼€å§‹å®‰å…¨è§£æ•£ {len(participating_agents)} ä¸ªæ™ºèƒ½ä½“")

            for agent in participating_agents:
                # åªå¤„ç†å…·èº«å«æ˜Ÿæ™ºèƒ½ä½“
                if hasattr(agent, 'satellite_id'):
                    satellite_id = agent.satellite_id

                    try:
                        # ğŸ¯ ADKæ ‡å‡†ï¼šåªæ¸…ç†çˆ¶æ™ºèƒ½ä½“å…³ç³»ï¼Œä¿æŒå…·èº«æ™ºèƒ½ä½“çŠ¶æ€
                        self._safely_remove_parent_relationship(agent, satellite_id)

                        # ğŸ”§ ä¿æŒé‡è¦çŠ¶æ€ï¼šä»»åŠ¡æ‰§è¡ŒçŠ¶æ€ã€èµ„æºçŠ¶æ€ç­‰
                        self._preserve_embodied_agent_state(agent, satellite_id)

                        logger.info(f"âœ… å«æ˜Ÿæ™ºèƒ½ä½“ {satellite_id} å·²å®‰å…¨è§£æ•£ï¼ˆçŠ¶æ€å·²ä¿æŒï¼‰")

                    except Exception as agent_error:
                        logger.warning(f"âš ï¸ è§£æ•£å«æ˜Ÿæ™ºèƒ½ä½“ {satellite_id} æ—¶å‡ºç°é—®é¢˜: {agent_error}")
                        # ç»§ç»­å¤„ç†å…¶ä»–æ™ºèƒ½ä½“ï¼Œä¸ä¸­æ–­æ•´ä¸ªè¿‡ç¨‹

            logger.info(f"âœ… æ‰€æœ‰æ™ºèƒ½ä½“å·²å®‰å…¨è§£æ•£ï¼Œå…·èº«çŠ¶æ€å·²ä¿æŒ")

        except Exception as e:
            logger.error(f"âŒ å®‰å…¨è§£æ•£æ™ºèƒ½ä½“å¤±è´¥: {e}")
            # ä¸æŠ›å‡ºå¼‚å¸¸ï¼Œç¡®ä¿è®¨è®ºç»„æ¸…ç†å¯ä»¥ç»§ç»­

    def _safely_remove_parent_relationship(self, agent, satellite_id: str):
        """
        å®‰å…¨ç§»é™¤æ™ºèƒ½ä½“çš„çˆ¶å…³ç³»ï¼ˆADKæ ‡å‡†æ–¹å¼ï¼‰

        åªæ¸…ç†ADKæ¡†æ¶çš„çˆ¶å­å…³ç³»ï¼Œä¸å½±å“å…·èº«æ™ºèƒ½ä½“æœ¬èº«
        """
        try:
            # ğŸ¯ ADKæ ‡å‡†ï¼šæ¸…ç†æ‰€æœ‰å¯èƒ½çš„çˆ¶æ™ºèƒ½ä½“å±æ€§
            parent_attributes = [
                '_parent_agent',    # ADKæ ‡å‡†çˆ¶æ™ºèƒ½ä½“å±æ€§
                'parent_agent',     # å¯èƒ½çš„åˆ«å
                '_adk_parent',      # ADKå†…éƒ¨çˆ¶å¼•ç”¨
                '_parent',          # é€šç”¨çˆ¶å¼•ç”¨
            ]

            for attr in parent_attributes:
                if hasattr(agent, attr):
                    old_parent = getattr(agent, attr)
                    if old_parent is not None:
                        logger.debug(f"   æ¸…ç† {satellite_id} çš„ {attr}: {getattr(old_parent, 'name', 'unknown')}")
                        setattr(agent, attr, None)

            # ğŸ”§ æ¸…ç†ADKå†…éƒ¨çŠ¶æ€ï¼ˆå¦‚æœå­˜åœ¨ï¼‰
            adk_internal_attributes = [
                '_sub_agents',      # å­æ™ºèƒ½ä½“åˆ—è¡¨
                '_discussion_id',   # è®¨è®ºç»„ID
                '_adk_context',     # ADKä¸Šä¸‹æ–‡
                '_adk_session',     # ADKä¼šè¯
            ]

            for attr in adk_internal_attributes:
                if hasattr(agent, attr):
                    setattr(agent, attr, None)
                    logger.debug(f"   æ¸…ç† {satellite_id} çš„ {attr}")

            logger.debug(f"âœ… {satellite_id} çš„çˆ¶å…³ç³»å·²å®‰å…¨æ¸…ç†")

        except Exception as e:
            logger.warning(f"âš ï¸ æ¸…ç† {satellite_id} çˆ¶å…³ç³»å¤±è´¥: {e}")
            # ä¸æŠ›å‡ºå¼‚å¸¸ï¼Œç»§ç»­å¤„ç†

    def _preserve_embodied_agent_state(self, agent, satellite_id: str):
        """
        ä¿æŒå…·èº«æ™ºèƒ½ä½“çš„é‡è¦çŠ¶æ€

        ç¡®ä¿ä¸‹æ¬¡æ»šåŠ¨è§„åˆ’å¯ä»¥æ­£ç¡®ä½¿ç”¨è¿™äº›çŠ¶æ€ï¼š
        1. ä»»åŠ¡æ‰§è¡Œå†å²å’ŒçŠ¶æ€
        2. èµ„æºä½¿ç”¨æƒ…å†µ
        3. æ€§èƒ½æŒ‡æ ‡
        4. åä½œç»éªŒ
        """
        try:
            # ğŸ¯ ä¿æŒçš„é‡è¦çŠ¶æ€ï¼ˆè¿™äº›çŠ¶æ€å¯¹ä¸‹æ¬¡æ»šåŠ¨è§„åˆ’å¾ˆé‡è¦ï¼‰
            preserved_states = [
                'satellite_id',           # å«æ˜ŸIDï¼ˆæ ¸å¿ƒæ ‡è¯†ï¼‰
                '_config',               # é…ç½®ä¿¡æ¯
                '_time_manager',         # æ—¶é—´ç®¡ç†å™¨
                '_stk_manager',          # STKç®¡ç†å™¨
                '_multi_agent_system',   # å¤šæ™ºèƒ½ä½“ç³»ç»Ÿå¼•ç”¨
                'memory_module',         # è®°å¿†æ¨¡å—
                '_task_history',         # ä»»åŠ¡å†å²
                '_resource_status',      # èµ„æºçŠ¶æ€
                '_performance_metrics',  # æ€§èƒ½æŒ‡æ ‡
                '_collaboration_history', # åä½œå†å²
                '_visibility_calculator', # å¯è§æ€§è®¡ç®—å™¨
                '_discussion_groups',    # è®¨è®ºç»„å†å²
            ]

            preserved_count = 0
            for state_attr in preserved_states:
                if hasattr(agent, state_attr):
                    # ç¡®ä¿è¿™äº›çŠ¶æ€ä¸è¢«æ„å¤–æ¸…ç†
                    value = getattr(agent, state_attr)
                    if value is not None:
                        preserved_count += 1
                        logger.debug(f"   ä¿æŒ {satellite_id}.{state_attr}")

            # ğŸ”§ é‡ç½®ä¸´æ—¶æ‰§è¡ŒçŠ¶æ€ï¼ˆä½†ä¿æŒé‡è¦çŠ¶æ€ï¼‰
            temporary_states = {
                '_last_response': None,      # æ¸…ç†ä¸Šæ¬¡å“åº”
                '_current_iteration': 0,     # é‡ç½®è¿­ä»£è®¡æ•°
                '_iteration_results': [],    # æ¸…ç†è¿­ä»£ç»“æœ
                '_discussion_state': None,   # æ¸…ç†è®¨è®ºçŠ¶æ€
            }

            for attr, default_value in temporary_states.items():
                if hasattr(agent, attr):
                    setattr(agent, attr, default_value)
                    logger.debug(f"   é‡ç½® {satellite_id}.{attr}")

            logger.debug(f"âœ… {satellite_id} çŠ¶æ€å·²ä¿æŒï¼š{preserved_count} ä¸ªé‡è¦çŠ¶æ€ä¿ç•™")

        except Exception as e:
            logger.warning(f"âš ï¸ ä¿æŒ {satellite_id} çŠ¶æ€å¤±è´¥: {e}")
            # ä¸æŠ›å‡ºå¼‚å¸¸ï¼Œç»§ç»­å¤„ç†

    def _create_adk_parallel_fanout_pattern(
        self,
        discussion_id: str,
        participating_agents: List[BaseAgent],
        task_description: str
    ) -> SequentialAgent:
        """
        åˆ›å»ºADKå®˜æ–¹Parallel Fan-Out/Gather Pattern

        æ ¹æ®ADKå®˜æ–¹æ–‡æ¡£ï¼š
        1. ParallelAgentå¹¶å‘æ‰§è¡Œæ‰€æœ‰æ™ºèƒ½ä½“
        2. LlmAgentèšåˆå™¨æ”¶é›†å’Œåˆ†æç»“æœ
        3. SequentialAgentç»„åˆFan-Outå’ŒGatheré˜¶æ®µ
        """
        from google.adk.agents import ParallelAgent, SequentialAgent, LlmAgent

        logger.info(f"ğŸ”„ åˆ›å»ºADKå®˜æ–¹Parallel Fan-Out/Gatheræ¨¡å¼: {discussion_id}")

        # é˜¶æ®µ1ï¼šParallel Fan-Out - æ‰€æœ‰æ™ºèƒ½ä½“å¹¶å‘æ‰§è¡Œ
        parallel_stage = ParallelAgent(
            name=f"ParallelFanOut_{discussion_id}",
            sub_agents=participating_agents
        )

        # é˜¶æ®µ2ï¼šGather - ä¸“ä¸šèšåˆå™¨ï¼ˆç»§æ‰¿çˆ¶ç±»çš„æ¨¡å‹é…ç½®ï¼‰
        gather_agent = LlmAgent(
            name=f"GatherAgent_{discussion_id}",
            model=self.model,  # ç»§æ‰¿ADKOfficialDiscussionSystemçš„æ¨¡å‹é…ç½®
            instruction=f"""
ä½ æ˜¯ä¸“ä¸šçš„ç»“æœèšåˆå™¨ï¼Œè´Ÿè´£æ”¶é›†å’Œæ·±åº¦åˆ†æå¹¶å‘æ‰§è¡Œçš„ç»“æœã€‚

ä»»åŠ¡æè¿°: {task_description}

è¯·æ‰§è¡Œä»¥ä¸‹ä¸“ä¸šåˆ†ææ­¥éª¤ï¼š

1. **ç»“æœæ”¶é›†ä¸æ•´ç†**ï¼š
   - æ”¶é›†æ‰€æœ‰å«æ˜Ÿæ™ºèƒ½ä½“çš„æ‰§è¡Œç»“æœ
   - æ•´ç†å„æ™ºèƒ½ä½“çš„åˆ†ææ•°æ®å’ŒæŒ‡æ ‡

2. **ä¸“ä¸šæŒ‡æ ‡è®¡ç®—**ï¼š
   - è®¡ç®—ç³»ç»Ÿçº§GDOPï¼ˆå‡ ä½•ç²¾åº¦å› å­ï¼Œè¶Šå°è¶Šå¥½ï¼Œç†æƒ³å€¼<2.0ï¼‰
   - è¯„ä¼°æ•´ä½“é²æ£’æ€§è¯„åˆ†
   - åˆ†æè¦†ç›–ç‡å’Œä»»åŠ¡å¯è¡Œæ€§
   - è®¡ç®—èµ„æºåˆ©ç”¨æ•ˆç‡

3. **æ·±åº¦åˆ†ææŠ¥å‘Š**ï¼š
   - åˆ†æç»“æœçš„ä¸€è‡´æ€§å’Œè´¨é‡
   - è¯†åˆ«æ½œåœ¨çš„ç³»ç»Ÿç“¶é¢ˆ
   - è¯„ä¼°ä»»åŠ¡æ‰§è¡Œé£é™©
   - æä¾›ä¼˜åŒ–å»ºè®®

4. **ç»“æ„åŒ–è¾“å‡º**ï¼š
   è¯·ä»¥ä»¥ä¸‹æ ¼å¼è¾“å‡ºåˆ†æç»“æœï¼š

   ## ç³»ç»Ÿçº§æŒ‡æ ‡
   - æ•´ä½“GDOP: [æ•°å€¼ï¼Œè¶Šå°è¶Šå¥½ï¼Œç†æƒ³å€¼<2.0]
   - ç³»ç»Ÿé²æ£’æ€§: [0-100è¯„åˆ†]
   - è¦†ç›–ç‡: [ç™¾åˆ†æ¯”]
   - èµ„æºåˆ©ç”¨ç‡: [ç™¾åˆ†æ¯”]

   ## è¯¦ç»†åˆ†æ
   [å…·ä½“åˆ†æå†…å®¹]

   ## ä¼˜åŒ–å»ºè®®
   [æ”¹è¿›å»ºè®®]

å°†èšåˆç»“æœä¿å­˜åˆ°session.state['fanout_gather_result']ä¸­ã€‚
""",
            output_key="fanout_gather_result"
        )

        # ç»„åˆFan-Outå’ŒGatheré˜¶æ®µ
        discussion_agent = SequentialAgent(
            name=f"ParallelFanOutGather_{discussion_id}",
            sub_agents=[parallel_stage, gather_agent]
        )

        # è®¾ç½®è®¨è®ºç»„å±æ€§
        discussion_agent._discussion_id = discussion_id
        discussion_agent._discussion_type = "parallel_fanout"
        discussion_agent._discussion_members = participating_agents
        discussion_agent._discussion_task = task_description
        discussion_agent._parallel_stage = parallel_stage
        discussion_agent._gather_stage = gather_agent

        logger.info(f"âœ… ADKå®˜æ–¹Parallel Fan-Out/Gatheræ¨¡å¼åˆ›å»ºå®Œæˆ: {discussion_id}")
        logger.info(f"   Fan-Outæ™ºèƒ½ä½“æ•°é‡: {len(participating_agents)}")
        logger.info(f"   Gatheræ™ºèƒ½ä½“: {gather_agent.name}")

        return discussion_agent

    def _create_adk_sequential_pipeline_pattern(
        self,
        discussion_id: str,
        participating_agents: List[BaseAgent],
        task_description: str
    ) -> SequentialAgent:
        """
        åˆ›å»ºADKå®˜æ–¹Sequential Pipeline Pattern

        æ ¹æ®ADKå®˜æ–¹æ–‡æ¡£ï¼š
        1. SequentialAgentæŒ‰é¡ºåºæ‰§è¡Œæ™ºèƒ½ä½“
        2. é€šè¿‡session.stateä¼ é€’æµæ°´çº¿ç»“æœ
        3. æ¯ä¸ªæ™ºèƒ½ä½“è¯»å–å‰ä¸€ä¸ªçš„è¾“å‡º
        """
        from google.adk.agents import SequentialAgent

        logger.info(f"ğŸ”„ åˆ›å»ºADKå®˜æ–¹Sequential Pipelineæ¨¡å¼: {discussion_id}")

        # ä¸ºæ¯ä¸ªæ™ºèƒ½ä½“è®¾ç½®æµæ°´çº¿é…ç½®
        for i, agent in enumerate(participating_agents):
            agent._pipeline_stage = i + 1
            agent._pipeline_task = f"æµæ°´çº¿ç¬¬{i+1}é˜¶æ®µ: {task_description}"
            logger.info(f"   ğŸ“‹ é…ç½®æµæ°´çº¿é˜¶æ®µ{i+1}: {agent.name}")

        # åˆ›å»ºé¡ºåºæµæ°´çº¿
        discussion_agent = SequentialAgent(
            name=f"SequentialPipeline_{discussion_id}",
            sub_agents=participating_agents
        )

        # è®¾ç½®è®¨è®ºç»„å±æ€§
        discussion_agent._discussion_id = discussion_id
        discussion_agent._discussion_type = "sequential_pipeline"
        discussion_agent._discussion_members = participating_agents
        discussion_agent._discussion_task = task_description

        logger.info(f"âœ… ADKå®˜æ–¹Sequential Pipelineæ¨¡å¼åˆ›å»ºå®Œæˆ: {discussion_id}")
        logger.info(f"   æµæ°´çº¿æ­¥éª¤æ•°é‡: {len(participating_agents)}")

        return discussion_agent

    def _create_adk_iterative_refinement_pattern(
        self,
        discussion_id: str,
        participating_agents: List[BaseAgent],
        task_description: str
    ) -> LoopAgent:
        """
        åˆ›å»ºADKå®˜æ–¹Iterative Refinement Pattern

        æ ¹æ®ADKå®˜æ–¹æ–‡æ¡£ï¼š
        1. LoopAgenté‡å¤æ‰§è¡Œsub_agents
        2. é€šè¿‡session.stateä¿æŒè¿­ä»£çŠ¶æ€
        3. é€šè¿‡escalate=Trueç»ˆæ­¢å¾ªç¯
        """
        from google.adk.agents import LoopAgent, SequentialAgent, LlmAgent, BaseAgent
        from google.adk.events import Event, EventActions
        from google.adk.agents.invocation_context import InvocationContext
        from typing import AsyncGenerator

        logger.info(f"ğŸ”„ åˆ›å»ºADKå®˜æ–¹Iterative Refinementæ¨¡å¼: {discussion_id}")

        # åˆ›å»ºå¹¶å‘æ‰§è¡Œé˜¶æ®µ
        parallel_stage = ParallelAgent(
            name=f"IterativeParallel_{discussion_id}",
            sub_agents=participating_agents
        )

        # åˆ›å»ºä¸“ä¸šè´¨é‡æ£€æŸ¥å’Œä¼˜åŒ–æ™ºèƒ½ä½“ï¼ˆç»§æ‰¿çˆ¶ç±»çš„æ¨¡å‹é…ç½®ï¼‰
        quality_checker = LlmAgent(
            name=f"QualityChecker_{discussion_id}",
            model=self.model,  # ç»§æ‰¿ADKOfficialDiscussionSystemçš„æ¨¡å‹é…ç½®
            instruction=f"""
ä½ æ˜¯ä¸“ä¸šçš„è´¨é‡æ£€æŸ¥å’Œä¼˜åŒ–æ™ºèƒ½ä½“ï¼Œè´Ÿè´£æ·±åº¦è¯„ä¼°è¿­ä»£ç»“æœå¹¶å†³å®šæ˜¯å¦ç»§ç»­ä¼˜åŒ–ã€‚

ä»»åŠ¡æè¿°: {task_description}

è¯·æ‰§è¡Œä»¥ä¸‹ä¸“ä¸šè¯„ä¼°æ­¥éª¤ï¼š

1. **å¤šç»´åº¦è´¨é‡è¯„ä¼°**ï¼š
   - GDOPè´¨é‡è¯„åˆ†ï¼ˆ0-1ï¼‰
   - é²æ£’æ€§è¯„åˆ†ï¼ˆ0-1ï¼‰
   - è¦†ç›–ç‡è¯„åˆ†ï¼ˆ0-1ï¼‰
   - èµ„æºæ•ˆç‡è¯„åˆ†ï¼ˆ0-1ï¼‰

2. **ç»¼åˆè´¨é‡è®¡ç®—**ï¼š
   - è®¡ç®—åŠ æƒç»¼åˆè´¨é‡åˆ†æ•°
   - æƒé‡ï¼šGDOP(0.3) + é²æ£’æ€§(0.3) + è¦†ç›–ç‡(0.2) + æ•ˆç‡(0.2)

3. **è¿­ä»£å†³ç­–é€»è¾‘**ï¼š
   - å¦‚æœç»¼åˆè´¨é‡åˆ†æ•° >= 0.85ï¼Œè®¾ç½®escalate=Trueåœæ­¢è¿­ä»£
   - å¦‚æœåˆ†æ•° < 0.6ï¼Œæä¾›å…·ä½“æ”¹è¿›å»ºè®®
   - å¦‚æœ0.6 <= åˆ†æ•° < 0.85ï¼Œè¿›è¡Œå¾®è°ƒä¼˜åŒ–

4. **ä¸“ä¸šæ”¹è¿›å»ºè®®**ï¼š
   - åŸºäºå…·ä½“æŒ‡æ ‡æä¾›ä¼˜åŒ–æ–¹å‘
   - è¯†åˆ«æ€§èƒ½ç“¶é¢ˆå’Œæ”¹è¿›ç‚¹
   - æä¾›é‡åŒ–çš„æ”¹è¿›ç›®æ ‡

è¯·ä»¥ç»“æ„åŒ–æ ¼å¼è¾“å‡ºè¯„ä¼°ç»“æœï¼š

## è´¨é‡è¯„ä¼°ç»“æœ
- GDOPè¯„åˆ†: [0-1]
- é²æ£’æ€§è¯„åˆ†: [0-1]
- è¦†ç›–ç‡è¯„åˆ†: [0-1]
- æ•ˆç‡è¯„åˆ†: [0-1]
- **ç»¼åˆè´¨é‡åˆ†æ•°: [0-1]**

## è¿­ä»£å†³ç­–
- æ˜¯å¦ç»§ç»­è¿­ä»£: [æ˜¯/å¦]
- å†³ç­–ç†ç”±: [å…·ä½“åŸå› ]

## æ”¹è¿›å»ºè®®
[å…·ä½“çš„ä¼˜åŒ–å»ºè®®]

å°†ç»“æœä¿å­˜åˆ°session.state['iterative_result']ä¸­ã€‚
å¦‚æœéœ€è¦åœæ­¢è¿­ä»£ï¼Œè®¾ç½®session.state['should_escalate'] = Trueã€‚
""",
            output_key="iterative_result"
        )

        # åˆ›å»ºè¿­ä»£åºåˆ—
        iteration_sequence = SequentialAgent(
            name=f"IterationSequence_{discussion_id}",
            sub_agents=[parallel_stage, quality_checker]
        )

        # åˆ›å»ºLoopAgent
        discussion_agent = LoopAgent(
            name=f"IterativeRefinement_{discussion_id}",
            max_iterations=5,
            sub_agents=[iteration_sequence]
        )

        # è®¾ç½®è®¨è®ºç»„å±æ€§
        discussion_agent._discussion_id = discussion_id
        discussion_agent._discussion_type = "iterative_refinement"
        discussion_agent._discussion_members = participating_agents
        discussion_agent._discussion_task = task_description

        logger.info(f"âœ… ADKå®˜æ–¹Iterative Refinementæ¨¡å¼åˆ›å»ºå®Œæˆ: {discussion_id}")
        logger.info(f"   å‚ä¸æ™ºèƒ½ä½“æ•°é‡: {len(participating_agents)}")
        logger.info(f"   æœ€å¤§è¿­ä»£æ¬¡æ•°: 5")

        return discussion_agent

    def __del__(self):
        """ææ„å‡½æ•°ï¼Œç¡®ä¿æ¸…ç†èµ„æº"""
        if self._lifecycle_monitor_task and not self._lifecycle_monitor_task.done():
            self._lifecycle_monitor_task.cancel()
            logger.info("ğŸ›‘ ç”Ÿå‘½å‘¨æœŸç›‘æ§å·²åœæ­¢")
