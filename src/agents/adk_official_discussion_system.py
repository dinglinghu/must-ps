"""
ADKå®˜æ–¹å¤šæ™ºèƒ½ä½“è®¨è®ºç³»ç»Ÿ
ä¸¥æ ¼æŒ‰ç…§Google ADKå®˜æ–¹æ–‡æ¡£çš„æœ€ä½³å®è·µè®¾è®¡
https://google.github.io/adk-docs/agents/multi-agents/

å®ç°çš„ADKå®˜æ–¹æ¨¡å¼ï¼š
1. Parallel Fan-Out/Gather Pattern - å¹¶å‘æ‰§è¡Œå’Œç»“æœèšåˆ
2. Sequential Pipeline Pattern - é¡ºåºæµæ°´çº¿å¤„ç†
3. Iterative Refinement Pattern - è¿­ä»£ä¼˜åŒ–è¿‡ç¨‹
4. ä¸¥æ ¼ä½¿ç”¨ADKæ™ºèƒ½ä½“é™åˆ¶ï¼Œä¸åˆ›å»ºè™šæ‹Ÿæ™ºèƒ½ä½“
"""

import asyncio
import logging
from datetime import datetime
from typing import List, Dict, Any
from uuid import uuid4

from google.adk.agents import BaseAgent, LlmAgent, SequentialAgent, ParallelAgent, LoopAgent
from google.adk.agents.invocation_context import InvocationContext
from google.adk.events import Event, EventActions
from google.genai import types

from src.utils.adk_session_manager import get_adk_session_manager

logger = logging.getLogger(__name__)

class ADKOfficialDiscussionSystem(BaseAgent):
    """
    ADKå®˜æ–¹å¤šæ™ºèƒ½ä½“è®¨è®ºç³»ç»Ÿ
    å®ç°å®˜æ–¹æ¨èçš„å¤šæ™ºèƒ½ä½“åä½œæ¨¡å¼
    """
    
    def __init__(self):
        super().__init__(
            name="ADKOfficialDiscussionSystem",
            description="åŸºäºADKå®˜æ–¹æ ‡å‡†çš„å¤šæ™ºèƒ½ä½“è®¨è®ºç³»ç»Ÿ"
        )
        
        # æ´»è·ƒè®¨è®ºç»„
        self._active_discussions: Dict[str, BaseAgent] = {}
        
        # ç”Ÿå‘½å‘¨æœŸç›‘æ§
        self._lifecycle_monitor_task = None
        self._auto_cleanup_enabled = True
        self._max_discussion_lifetime = 600  # 10åˆ†é’Ÿæœ€å¤§ç”Ÿå‘½å‘¨æœŸ
        
        logger.info("âœ… ADKå®˜æ–¹è®¨è®ºç³»ç»Ÿåˆå§‹åŒ–å®Œæˆ")

        # å¯åŠ¨ç”Ÿå‘½å‘¨æœŸç›‘æ§
        self._ensure_lifecycle_monitoring()

    def _ensure_lifecycle_monitoring(self):
        """ç¡®ä¿ç”Ÿå‘½å‘¨æœŸç›‘æ§å·²å¯åŠ¨"""
        try:
            # æ£€æŸ¥æ˜¯å¦æœ‰è¿è¡Œçš„äº‹ä»¶å¾ªç¯
            loop = asyncio.get_running_loop()
            if self._lifecycle_monitor_task is None or self._lifecycle_monitor_task.done():
                self._lifecycle_monitor_task = loop.create_task(self._lifecycle_monitor())
                logger.info("âœ… ADKå®˜æ–¹è®¨è®ºç³»ç»Ÿç”Ÿå‘½å‘¨æœŸç›‘æ§å·²å¯åŠ¨")
        except RuntimeError:
            # æ²¡æœ‰è¿è¡Œçš„äº‹ä»¶å¾ªç¯ï¼ˆå¦‚åœ¨FlaskåŒæ­¥ç¯å¢ƒä¸­ï¼‰
            logger.info("âš ï¸ æ²¡æœ‰è¿è¡Œçš„äº‹ä»¶å¾ªç¯ï¼Œç”Ÿå‘½å‘¨æœŸç›‘æ§å°†åœ¨éœ€è¦æ—¶å¯åŠ¨")
            self._lifecycle_monitor_task = None

    async def start_lifecycle_monitoring_async(self):
        """åœ¨å¼‚æ­¥ç¯å¢ƒä¸­å¯åŠ¨ç”Ÿå‘½å‘¨æœŸç›‘æ§"""
        try:
            if self._lifecycle_monitor_task is None or self._lifecycle_monitor_task.done():
                self._lifecycle_monitor_task = asyncio.create_task(self._lifecycle_monitor())
                logger.info("âœ… ADKå®˜æ–¹è®¨è®ºç³»ç»Ÿç”Ÿå‘½å‘¨æœŸç›‘æ§å·²å¯åŠ¨ï¼ˆå¼‚æ­¥æ¨¡å¼ï¼‰")
                return True
            return False
        except Exception as e:
            logger.error(f"âŒ å¯åŠ¨ç”Ÿå‘½å‘¨æœŸç›‘æ§å¤±è´¥: {e}")
            return False

    async def _lifecycle_monitor(self):
        """ç”Ÿå‘½å‘¨æœŸç›‘æ§ä»»åŠ¡"""
        try:
            while self._auto_cleanup_enabled:
                await asyncio.sleep(60)  # æ¯åˆ†é’Ÿæ£€æŸ¥ä¸€æ¬¡
                await self._cleanup_expired_discussions()
        except asyncio.CancelledError:
            logger.info("ğŸ›‘ ç”Ÿå‘½å‘¨æœŸç›‘æ§å·²åœæ­¢")
        except Exception as e:
            logger.error(f"âŒ ç”Ÿå‘½å‘¨æœŸç›‘æ§å¼‚å¸¸: {e}")

    async def _cleanup_expired_discussions(self):
        """æ¸…ç†è¿‡æœŸçš„è®¨è®ºç»„"""
        try:
            current_time = datetime.now()
            expired_discussions = []
            
            for discussion_id, discussion_agent in self._active_discussions.items():
                creation_time = getattr(discussion_agent, '_creation_time', current_time)
                if (current_time - creation_time).total_seconds() > self._max_discussion_lifetime:
                    expired_discussions.append(discussion_id)
            
            for discussion_id in expired_discussions:
                await self.complete_discussion(discussion_id)
                logger.info(f"ğŸ§¹ å·²æ¸…ç†è¿‡æœŸè®¨è®ºç»„: {discussion_id}")
                
        except Exception as e:
            logger.error(f"âŒ æ¸…ç†è¿‡æœŸè®¨è®ºç»„å¤±è´¥: {e}")

    async def create_discussion_with_adk_patterns(
        self,
        pattern_type: str,
        participating_agents: List[BaseAgent],
        task_description: str
    ) -> str:
        """
        ä½¿ç”¨ADKå®˜æ–¹å¤šæ™ºèƒ½ä½“æ¨¡å¼åˆ›å»ºè®¨è®ºç»„
        ä¸¥æ ¼æŒ‰ç…§ADKå®˜æ–¹æ–‡æ¡£çš„Parallel Fan-Out/Gather Patternè®¾è®¡

        Args:
            pattern_type: åä½œæ¨¡å¼ ("parallel_fanout", "sequential_pipeline", "iterative_refinement")
            participating_agents: å‚ä¸è®¨è®ºçš„å…·èº«å«æ˜Ÿæ™ºèƒ½ä½“åˆ—è¡¨
            task_description: ä»»åŠ¡æè¿°

        Returns:
            è®¨è®ºID
        """
        try:
            from google.adk.agents import ParallelAgent, SequentialAgent, LlmAgent

            logger.info(f"ğŸ”„ ä½¿ç”¨ADKå®˜æ–¹æ¨¡å¼åˆ›å»ºè®¨è®ºç»„: {pattern_type}")
            logger.info(f"   å‚ä¸æ™ºèƒ½ä½“: {[agent.name for agent in participating_agents]}")
            logger.info(f"   ä»»åŠ¡æè¿°: {task_description}")

            # ç¡®ä¿ç”Ÿå‘½å‘¨æœŸç›‘æ§å·²å¯åŠ¨
            self._ensure_lifecycle_monitoring()

            # å¦‚æœåœ¨å¼‚æ­¥ç¯å¢ƒä¸­ï¼Œå°è¯•å¯åŠ¨å¼‚æ­¥ç”Ÿå‘½å‘¨æœŸç›‘æ§
            if self._lifecycle_monitor_task is None:
                await self.start_lifecycle_monitoring_async()

            # æ£€æŸ¥å¹¶æ¸…ç†æ™ºèƒ½ä½“çš„æ—§å…³ç³»
            await self._cleanup_agents_old_relationships(participating_agents)

            # å¼ºåˆ¶é‡ç½®æ™ºèƒ½ä½“çŠ¶æ€
            await self._force_reset_agents(participating_agents)

            # ç”Ÿæˆè®¨è®ºç»„ID
            discussion_id = f"adk_official_{uuid4().hex[:8]}"

            # éªŒè¯å‚ä¸æ™ºèƒ½ä½“éƒ½æ˜¯å…·èº«å«æ˜Ÿæ™ºèƒ½ä½“
            for agent in participating_agents:
                if not hasattr(agent, 'satellite_id'):
                    raise ValueError(f"æ™ºèƒ½ä½“ {agent.name} ä¸æ˜¯å…·èº«å«æ˜Ÿæ™ºèƒ½ä½“")

            # æŒ‰ç…§ADKå®˜æ–¹æ¨¡å¼åˆ›å»ºè®¨è®ºç»„æ™ºèƒ½ä½“
            if pattern_type == "parallel_fanout":
                # Parallel Fan-Out/Gather Pattern - ADKå®˜æ–¹æ¨èæ¨¡å¼
                discussion_agent = self._create_adk_parallel_fanout_pattern(
                    discussion_id, participating_agents, task_description
                )
            elif pattern_type == "sequential_pipeline":
                # Sequential Pipeline Pattern - ADKå®˜æ–¹æ¨èæ¨¡å¼
                discussion_agent = self._create_adk_sequential_pipeline_pattern(
                    discussion_id, participating_agents, task_description
                )
            elif pattern_type == "iterative_refinement":
                # Iterative Refinement Pattern - ADKå®˜æ–¹æ¨èæ¨¡å¼
                discussion_agent = self._create_adk_iterative_refinement_pattern(
                    discussion_id, participating_agents, task_description
                )
            else:
                raise ValueError(f"ä¸æ”¯æŒçš„åä½œæ¨¡å¼: {pattern_type}")

            # è®¾ç½®åˆ›å»ºæ—¶é—´
            discussion_agent._creation_time = datetime.now()

            # æ³¨å†Œè®¨è®ºç»„
            self._active_discussions[discussion_id] = discussion_agent

            # æ³¨å†Œåˆ°ADK Sessionç®¡ç†å™¨
            session_manager = get_adk_session_manager()
            discussion_info = {
                'discussion_id': discussion_id,
                'pattern_type': pattern_type,
                'agent_count': len(participating_agents),
                'task_description': task_description,
                'creation_time': datetime.now().isoformat()
            }
            session_manager.add_adk_discussion(discussion_id, discussion_info)

            logger.info(f"âœ… ADKå®˜æ–¹æ¨¡å¼è®¨è®ºç»„åˆ›å»ºæˆåŠŸ: {discussion_id} (æ¨¡å¼: {pattern_type})")
            logger.info(f"   è®¨è®ºç»„ç±»å‹: {discussion_agent.__class__.__name__}")
            logger.info(f"   ä½¿ç”¨ADKåŸç”ŸInvocationContextï¼Œè‡ªåŠ¨æ”¯æŒmodel_copy")

            return discussion_id

        except Exception as e:
            logger.error(f"âŒ ä½¿ç”¨ADKå®˜æ–¹æ¨¡å¼åˆ›å»ºè®¨è®ºç»„å¤±è´¥: {e}")
            raise

    async def create_discussion(
        self,
        pattern_type: str,
        participating_agents: List[BaseAgent],
        task_description: str,
        ctx=None
    ) -> str:
        """
        åˆ›å»ºADKå®˜æ–¹å¤šæ™ºèƒ½ä½“è®¨è®ºç»„ï¼ˆå‘åå…¼å®¹æ–¹æ³•ï¼‰

        è¿™ä¸ªæ–¹æ³•ä¿æŒå‘åå…¼å®¹ï¼Œä½†å†…éƒ¨ä½¿ç”¨æ–°çš„Runneræ–¹å¼

        Args:
            pattern_type: åä½œæ¨¡å¼
            participating_agents: å‚ä¸è®¨è®ºçš„å…·èº«å«æ˜Ÿæ™ºèƒ½ä½“åˆ—è¡¨
            task_description: ä»»åŠ¡æè¿°
            ctx: ä¸Šä¸‹æ–‡ï¼ˆå°†è¢«å¿½ç•¥ï¼Œä½¿ç”¨Runnerè‡ªåŠ¨åˆ›å»ºï¼‰

        Returns:
            è®¨è®ºID
        """
        logger.info(f"ğŸ”„ åˆ›å»ºADKè®¨è®ºç»„ï¼ˆå…¼å®¹æ¨¡å¼ï¼‰: {pattern_type}")

        # å†…éƒ¨è°ƒç”¨æ–°çš„ADKå®˜æ–¹æ¨¡å¼
        return await self.create_discussion_with_adk_patterns(
            pattern_type=pattern_type,
            participating_agents=participating_agents,
            task_description=task_description
        )

    async def _cleanup_agents_old_relationships(self, agents: List[BaseAgent]):
        """æ£€æŸ¥å¹¶æ¸…ç†æ™ºèƒ½ä½“çš„æ—§å…³ç³»"""
        logger.info(f"ğŸ§¹ æ£€æŸ¥å¹¶æ¸…ç† {len(agents)} ä¸ªæ™ºèƒ½ä½“çš„æ—§å…³ç³»")
        
        for agent in agents:
            # æ£€æŸ¥æ˜¯å¦æœ‰æ—§çš„çˆ¶å­å…³ç³»
            if hasattr(agent, '_parent_agent'):
                delattr(agent, '_parent_agent')
            if hasattr(agent, '_sub_agents'):
                delattr(agent, '_sub_agents')
            if hasattr(agent, '_discussion_id'):
                delattr(agent, '_discussion_id')
        
        logger.info("âœ… æ‰€æœ‰æ™ºèƒ½ä½“éƒ½æ²¡æœ‰æ—§çš„çˆ¶å­å…³ç³»")

    async def _force_reset_agents(self, agents: List[BaseAgent]):
        """å¼ºåˆ¶é‡ç½®æ™ºèƒ½ä½“çŠ¶æ€"""
        logger.info(f"ğŸ”§ å¼ºåˆ¶é‡ç½® {len(agents)} ä¸ªæ™ºèƒ½ä½“çŠ¶æ€")
        
        for agent in agents:
            # é‡ç½®æ™ºèƒ½ä½“çš„å†…éƒ¨çŠ¶æ€
            if hasattr(agent, '_last_response'):
                agent._last_response = None
            if hasattr(agent, '_execution_count'):
                agent._execution_count = 0
        
        logger.info("âœ… æ‰€æœ‰æ™ºèƒ½ä½“çŠ¶æ€é‡ç½®å®Œæˆ")

    async def complete_discussion(self, discussion_id: str) -> bool:
        """å®Œæˆå¹¶æ¸…ç†è®¨è®ºç»„"""
        try:
            if discussion_id in self._active_discussions:
                discussion_agent = self._active_discussions[discussion_id]
                
                # æ¸…ç†è®¨è®ºç»„
                del self._active_discussions[discussion_id]
                
                # ä»Sessionç®¡ç†å™¨ä¸­ç§»é™¤
                session_manager = get_adk_session_manager()
                session_manager.remove_adk_discussion(discussion_id)
                
                logger.info(f"âœ… è®¨è®ºç»„å·²å®Œæˆå¹¶æ¸…ç†: {discussion_id}")
                return True
            else:
                logger.warning(f"âš ï¸ è®¨è®ºç»„ä¸å­˜åœ¨: {discussion_id}")
                return False
                
        except Exception as e:
            logger.error(f"âŒ å®Œæˆè®¨è®ºç»„å¤±è´¥: {e}")
            return False

    def _create_adk_parallel_fanout_pattern(
        self,
        discussion_id: str,
        participating_agents: List[BaseAgent],
        task_description: str
    ) -> SequentialAgent:
        """
        åˆ›å»ºADKå®˜æ–¹Parallel Fan-Out/Gather Pattern

        æ ¹æ®ADKå®˜æ–¹æ–‡æ¡£ï¼š
        1. ParallelAgentå¹¶å‘æ‰§è¡Œæ‰€æœ‰æ™ºèƒ½ä½“
        2. LlmAgentèšåˆå™¨æ”¶é›†å’Œåˆ†æç»“æœ
        3. SequentialAgentç»„åˆFan-Outå’ŒGatheré˜¶æ®µ
        """
        from google.adk.agents import ParallelAgent, SequentialAgent, LlmAgent

        logger.info(f"ğŸ”„ åˆ›å»ºADKå®˜æ–¹Parallel Fan-Out/Gatheræ¨¡å¼: {discussion_id}")

        # é˜¶æ®µ1ï¼šParallel Fan-Out - æ‰€æœ‰æ™ºèƒ½ä½“å¹¶å‘æ‰§è¡Œ
        parallel_stage = ParallelAgent(
            name=f"ParallelFanOut_{discussion_id}",
            sub_agents=participating_agents
        )

        # é˜¶æ®µ2ï¼šGather - èšåˆå™¨æ”¶é›†ç»“æœ
        gather_agent = LlmAgent(
            name=f"GatherAgent_{discussion_id}",
            model="gemini-2.0-flash",
            instruction=f"""
ä½ æ˜¯ç»“æœèšåˆå™¨ï¼Œè´Ÿè´£æ”¶é›†å’Œåˆ†æå¹¶å‘æ‰§è¡Œçš„ç»“æœã€‚

ä»»åŠ¡æè¿°: {task_description}

è¯·æ‰§è¡Œä»¥ä¸‹æ­¥éª¤ï¼š
1. æ”¶é›†æ‰€æœ‰æ™ºèƒ½ä½“çš„æ‰§è¡Œç»“æœ
2. åˆ†æç»“æœçš„ä¸€è‡´æ€§å’Œè´¨é‡
3. ç”Ÿæˆç»¼åˆæ€§çš„åˆ†ææŠ¥å‘Š
4. æä¾›æ”¹è¿›å»ºè®®

å°†èšåˆç»“æœä¿å­˜åˆ°session.state['fanout_gather_result']ä¸­ã€‚
""",
            output_key="fanout_gather_result"
        )

        # ç»„åˆFan-Outå’ŒGatheré˜¶æ®µ
        discussion_agent = SequentialAgent(
            name=f"ParallelFanOutGather_{discussion_id}",
            sub_agents=[parallel_stage, gather_agent]
        )

        # è®¾ç½®è®¨è®ºç»„å±æ€§
        discussion_agent._discussion_id = discussion_id
        discussion_agent._discussion_type = "parallel_fanout"
        discussion_agent._discussion_members = participating_agents
        discussion_agent._discussion_task = task_description
        discussion_agent._parallel_stage = parallel_stage
        discussion_agent._gather_stage = gather_agent

        logger.info(f"âœ… ADKå®˜æ–¹Parallel Fan-Out/Gatheræ¨¡å¼åˆ›å»ºå®Œæˆ: {discussion_id}")
        logger.info(f"   Fan-Outæ™ºèƒ½ä½“æ•°é‡: {len(participating_agents)}")
        logger.info(f"   Gatheræ™ºèƒ½ä½“: {gather_agent.name}")

        return discussion_agent

    def _create_adk_sequential_pipeline_pattern(
        self,
        discussion_id: str,
        participating_agents: List[BaseAgent],
        task_description: str
    ) -> SequentialAgent:
        """
        åˆ›å»ºADKå®˜æ–¹Sequential Pipeline Pattern

        æ ¹æ®ADKå®˜æ–¹æ–‡æ¡£ï¼š
        1. SequentialAgentæŒ‰é¡ºåºæ‰§è¡Œæ™ºèƒ½ä½“
        2. é€šè¿‡session.stateä¼ é€’æµæ°´çº¿ç»“æœ
        3. æ¯ä¸ªæ™ºèƒ½ä½“è¯»å–å‰ä¸€ä¸ªçš„è¾“å‡º
        """
        from google.adk.agents import SequentialAgent

        logger.info(f"ğŸ”„ åˆ›å»ºADKå®˜æ–¹Sequential Pipelineæ¨¡å¼: {discussion_id}")

        # ä¸ºæ¯ä¸ªæ™ºèƒ½ä½“è®¾ç½®æµæ°´çº¿é…ç½®
        for i, agent in enumerate(participating_agents):
            agent._pipeline_stage = i + 1
            agent._pipeline_task = f"æµæ°´çº¿ç¬¬{i+1}é˜¶æ®µ: {task_description}"
            logger.info(f"   ğŸ“‹ é…ç½®æµæ°´çº¿é˜¶æ®µ{i+1}: {agent.name}")

        # åˆ›å»ºé¡ºåºæµæ°´çº¿
        discussion_agent = SequentialAgent(
            name=f"SequentialPipeline_{discussion_id}",
            sub_agents=participating_agents
        )

        # è®¾ç½®è®¨è®ºç»„å±æ€§
        discussion_agent._discussion_id = discussion_id
        discussion_agent._discussion_type = "sequential_pipeline"
        discussion_agent._discussion_members = participating_agents
        discussion_agent._discussion_task = task_description

        logger.info(f"âœ… ADKå®˜æ–¹Sequential Pipelineæ¨¡å¼åˆ›å»ºå®Œæˆ: {discussion_id}")
        logger.info(f"   æµæ°´çº¿æ­¥éª¤æ•°é‡: {len(participating_agents)}")

        return discussion_agent

    def _create_adk_iterative_refinement_pattern(
        self,
        discussion_id: str,
        participating_agents: List[BaseAgent],
        task_description: str
    ) -> LoopAgent:
        """
        åˆ›å»ºADKå®˜æ–¹Iterative Refinement Pattern

        æ ¹æ®ADKå®˜æ–¹æ–‡æ¡£ï¼š
        1. LoopAgenté‡å¤æ‰§è¡Œsub_agents
        2. é€šè¿‡session.stateä¿æŒè¿­ä»£çŠ¶æ€
        3. é€šè¿‡escalate=Trueç»ˆæ­¢å¾ªç¯
        """
        from google.adk.agents import LoopAgent, SequentialAgent, LlmAgent, BaseAgent
        from google.adk.events import Event, EventActions
        from google.adk.agents.invocation_context import InvocationContext
        from typing import AsyncGenerator

        logger.info(f"ğŸ”„ åˆ›å»ºADKå®˜æ–¹Iterative Refinementæ¨¡å¼: {discussion_id}")

        # åˆ›å»ºå¹¶å‘æ‰§è¡Œé˜¶æ®µ
        parallel_stage = ParallelAgent(
            name=f"IterativeParallel_{discussion_id}",
            sub_agents=participating_agents
        )

        # åˆ›å»ºè´¨é‡æ£€æŸ¥å’Œä¼˜åŒ–æ™ºèƒ½ä½“
        quality_checker = LlmAgent(
            name=f"QualityChecker_{discussion_id}",
            model="gemini-2.0-flash",
            instruction=f"""
ä½ æ˜¯è´¨é‡æ£€æŸ¥å’Œä¼˜åŒ–æ™ºèƒ½ä½“ï¼Œè´Ÿè´£è¯„ä¼°è¿­ä»£ç»“æœå¹¶å†³å®šæ˜¯å¦ç»§ç»­ã€‚

ä»»åŠ¡æè¿°: {task_description}

è¯·æ‰§è¡Œä»¥ä¸‹æ­¥éª¤ï¼š
1. è¯„ä¼°å½“å‰è¿­ä»£çš„ç»“æœè´¨é‡
2. è®¡ç®—è´¨é‡åˆ†æ•°ï¼ˆ0-1ä¹‹é—´ï¼‰
3. å¦‚æœè´¨é‡åˆ†æ•° >= 0.8ï¼Œè®¾ç½®escalate=Trueåœæ­¢è¿­ä»£
4. å¦åˆ™æä¾›æ”¹è¿›å»ºè®®å¹¶ç»§ç»­è¿­ä»£

å°†ç»“æœä¿å­˜åˆ°session.state['iterative_result']ä¸­ã€‚
å¦‚æœéœ€è¦åœæ­¢è¿­ä»£ï¼Œè®¾ç½®session.state['should_escalate'] = Trueã€‚
""",
            output_key="iterative_result"
        )

        # åˆ›å»ºè¿­ä»£åºåˆ—
        iteration_sequence = SequentialAgent(
            name=f"IterationSequence_{discussion_id}",
            sub_agents=[parallel_stage, quality_checker]
        )

        # åˆ›å»ºLoopAgent
        discussion_agent = LoopAgent(
            name=f"IterativeRefinement_{discussion_id}",
            max_iterations=10,
            sub_agents=[iteration_sequence]
        )

        # è®¾ç½®è®¨è®ºç»„å±æ€§
        discussion_agent._discussion_id = discussion_id
        discussion_agent._discussion_type = "iterative_refinement"
        discussion_agent._discussion_members = participating_agents
        discussion_agent._discussion_task = task_description

        logger.info(f"âœ… ADKå®˜æ–¹Iterative Refinementæ¨¡å¼åˆ›å»ºå®Œæˆ: {discussion_id}")
        logger.info(f"   å‚ä¸æ™ºèƒ½ä½“æ•°é‡: {len(participating_agents)}")
        logger.info(f"   æœ€å¤§è¿­ä»£æ¬¡æ•°: 10")

        return discussion_agent

    def __del__(self):
        """ææ„å‡½æ•°ï¼Œç¡®ä¿æ¸…ç†èµ„æº"""
        if self._lifecycle_monitor_task and not self._lifecycle_monitor_task.done():
            self._lifecycle_monitor_task.cancel()
            logger.info("ğŸ›‘ ç”Ÿå‘½å‘¨æœŸç›‘æ§å·²åœæ­¢")
