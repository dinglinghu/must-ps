"""
å¤§æ¨¡å‹é…ç½®ç®¡ç†å™¨
ç»Ÿä¸€ç®¡ç†å¤§æ¨¡å‹é…ç½®ã€APIå¯†é’¥å’Œæ™ºèƒ½ä½“æç¤ºè¯
æ”¯æŒLiteLLMç»Ÿä¸€æ¥å£
"""

import os
import logging
from typing import Dict, Any, Optional, List
from dataclasses import dataclass
import yaml

logger = logging.getLogger(__name__)


@dataclass
class LLMConfig:
    """å¤§æ¨¡å‹é…ç½®æ•°æ®ç±»"""
    provider: str
    model: str
    api_key: Optional[str] = None
    api_key_env: Optional[str] = None
    base_url: Optional[str] = None
    api_version: Optional[str] = None
    max_tokens: int = 4096
    temperature: float = 0.7
    top_p: float = 0.9
    frequency_penalty: float = 0.0
    presence_penalty: float = 0.0
    timeout: int = 30
    retry_attempts: int = 3
    retry_delay: int = 1


@dataclass
class AgentPromptConfig:
    """æ™ºèƒ½ä½“æç¤ºè¯é…ç½®æ•°æ®ç±»"""
    system_prompt: str
    user_prompt_template: str
    few_shot_examples: List[Dict[str, str]]


class LLMConfigManager:
    """å¤§æ¨¡å‹é…ç½®ç®¡ç†å™¨"""
    
    def __init__(self, config_path: str = "config/config.yaml"):
        """
        åˆå§‹åŒ–é…ç½®ç®¡ç†å™¨
        
        Args:
            config_path: é…ç½®æ–‡ä»¶è·¯å¾„
        """
        self.config_path = config_path
        self.config = self._load_config()
        self.llm_config = self.config.get('llm', {})
        self.agent_prompts = self.config.get('agent_prompts', {})
        
        logger.info("ğŸ”§ å¤§æ¨¡å‹é…ç½®ç®¡ç†å™¨åˆå§‹åŒ–å®Œæˆ")
    
    def _load_config(self) -> Dict[str, Any]:
        """åŠ è½½é…ç½®æ–‡ä»¶"""
        try:
            with open(self.config_path, 'r', encoding='utf-8') as f:
                config = yaml.safe_load(f)
            logger.info(f"âœ… é…ç½®æ–‡ä»¶åŠ è½½æˆåŠŸ: {self.config_path}")
            return config
        except Exception as e:
            logger.error(f"âŒ é…ç½®æ–‡ä»¶åŠ è½½å¤±è´¥: {e}")
            return {}
    
    def get_llm_config(self, agent_type: Optional[str] = None) -> LLMConfig:
        """
        è·å–å¤§æ¨¡å‹é…ç½®
        
        Args:
            agent_type: æ™ºèƒ½ä½“ç±»å‹ï¼Œå¦‚æœæŒ‡å®šåˆ™ä½¿ç”¨ç‰¹å®šé…ç½®
            
        Returns:
            LLMConfig: å¤§æ¨¡å‹é…ç½®å¯¹è±¡
        """
        # è·å–ä¸»è¦é…ç½®
        primary_config = self.llm_config.get('primary', {})
        
        # å¦‚æœæŒ‡å®šäº†æ™ºèƒ½ä½“ç±»å‹ï¼Œå°è¯•è·å–ç‰¹å®šé…ç½®
        if agent_type:
            agent_specific = self.llm_config.get('agent_specific', {})
            specific_config = agent_specific.get(agent_type, {})
            # åˆå¹¶é…ç½®ï¼Œç‰¹å®šé…ç½®è¦†ç›–é»˜è®¤é…ç½®
            primary_config = {**primary_config, **specific_config}
        
        # å¤„ç†APIå¯†é’¥
        api_key = primary_config.get('api_key')
        api_key_env = primary_config.get('api_key_env')
        
        if not api_key and api_key_env:
            api_key = os.getenv(api_key_env)
            if not api_key:
                logger.warning(f"âš ï¸ ç¯å¢ƒå˜é‡ {api_key_env} æœªè®¾ç½®")
        
        return LLMConfig(
            provider=primary_config.get('provider', 'google'),
            model=primary_config.get('model', 'gemini-2.0-flash'),
            api_key=api_key,
            api_key_env=api_key_env,
            base_url=primary_config.get('base_url'),
            api_version=primary_config.get('api_version'),
            max_tokens=primary_config.get('max_tokens', 4096),
            temperature=primary_config.get('temperature', 0.7),
            top_p=primary_config.get('top_p', 0.9),
            frequency_penalty=primary_config.get('frequency_penalty', 0.0),
            presence_penalty=primary_config.get('presence_penalty', 0.0),
            timeout=primary_config.get('timeout', 30),
            retry_attempts=primary_config.get('retry_attempts', 3),
            retry_delay=primary_config.get('retry_delay', 1)
        )
    
    def get_fallback_configs(self) -> List[LLMConfig]:
        """
        è·å–å¤‡ç”¨æ¨¡å‹é…ç½®åˆ—è¡¨
        
        Returns:
            List[LLMConfig]: å¤‡ç”¨æ¨¡å‹é…ç½®åˆ—è¡¨
        """
        fallback_configs = []
        fallback_list = self.llm_config.get('fallback', [])
        
        for fallback in fallback_list:
            # å¤„ç†APIå¯†é’¥
            api_key = fallback.get('api_key')
            api_key_env = fallback.get('api_key_env')
            
            if not api_key and api_key_env:
                api_key = os.getenv(api_key_env)
            
            config = LLMConfig(
                provider=fallback.get('provider'),
                model=fallback.get('model'),
                api_key=api_key,
                api_key_env=api_key_env,
                base_url=fallback.get('base_url'),
                api_version=fallback.get('api_version'),
                max_tokens=fallback.get('max_tokens', 4096),
                temperature=fallback.get('temperature', 0.7),
                top_p=fallback.get('top_p', 0.9),
                frequency_penalty=fallback.get('frequency_penalty', 0.0),
                presence_penalty=fallback.get('presence_penalty', 0.0),
                timeout=fallback.get('timeout', 30),
                retry_attempts=fallback.get('retry_attempts', 3),
                retry_delay=fallback.get('retry_delay', 1)
            )
            fallback_configs.append(config)
        
        return fallback_configs
    
    def get_agent_prompt_config(self, agent_type: str) -> AgentPromptConfig:
        """
        è·å–æ™ºèƒ½ä½“æç¤ºè¯é…ç½®
        
        Args:
            agent_type: æ™ºèƒ½ä½“ç±»å‹
            
        Returns:
            AgentPromptConfig: æ™ºèƒ½ä½“æç¤ºè¯é…ç½®å¯¹è±¡
        """
        prompt_config = self.agent_prompts.get(agent_type, {})
        
        if not prompt_config:
            logger.warning(f"âš ï¸ æœªæ‰¾åˆ°æ™ºèƒ½ä½“ç±»å‹ {agent_type} çš„æç¤ºè¯é…ç½®")
            # è¿”å›é»˜è®¤é…ç½®
            return AgentPromptConfig(
                system_prompt="ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„æ™ºèƒ½ä½“ï¼Œè¯·ååŠ©å®Œæˆä»»åŠ¡ã€‚",
                user_prompt_template="ä»»åŠ¡: {task}",
                few_shot_examples=[]
            )
        
        return AgentPromptConfig(
            system_prompt=prompt_config.get('system_prompt', ''),
            user_prompt_template=prompt_config.get('user_prompt_template', ''),
            few_shot_examples=prompt_config.get('few_shot_examples', [])
        )
    
    def get_common_instructions(self) -> Dict[str, str]:
        """
        è·å–é€šç”¨æŒ‡ä»¤
        
        Returns:
            Dict[str, str]: é€šç”¨æŒ‡ä»¤å­—å…¸
        """
        common_config = self.agent_prompts.get('common', {})
        return {
            'global_instructions': common_config.get('global_instructions', ''),
            'error_handling': common_config.get('error_handling', ''),
            'collaboration': common_config.get('collaboration', ''),
            'security': common_config.get('security', '')
        }
    
    def format_system_prompt(self, agent_type: str, **kwargs) -> str:
        """
        æ ¼å¼åŒ–ç³»ç»Ÿæç¤ºè¯
        
        Args:
            agent_type: æ™ºèƒ½ä½“ç±»å‹
            **kwargs: æ ¼å¼åŒ–å‚æ•°
            
        Returns:
            str: æ ¼å¼åŒ–åçš„ç³»ç»Ÿæç¤ºè¯
        """
        prompt_config = self.get_agent_prompt_config(agent_type)
        common_instructions = self.get_common_instructions()
        
        # ç»„åˆç³»ç»Ÿæç¤ºè¯
        full_prompt = prompt_config.system_prompt
        
        # æ·»åŠ é€šç”¨æŒ‡ä»¤
        if common_instructions['global_instructions']:
            full_prompt += "\n\n" + common_instructions['global_instructions']
        
        # æ ¼å¼åŒ–æç¤ºè¯
        try:
            formatted_prompt = full_prompt.format(**kwargs)
        except KeyError as e:
            logger.warning(f"âš ï¸ æç¤ºè¯æ ¼å¼åŒ–ç¼ºå°‘å‚æ•°: {e}")
            formatted_prompt = full_prompt
        
        return formatted_prompt
    
    def format_user_prompt(self, agent_type: str, **kwargs) -> str:
        """
        æ ¼å¼åŒ–ç”¨æˆ·æç¤ºè¯
        
        Args:
            agent_type: æ™ºèƒ½ä½“ç±»å‹
            **kwargs: æ ¼å¼åŒ–å‚æ•°
            
        Returns:
            str: æ ¼å¼åŒ–åçš„ç”¨æˆ·æç¤ºè¯
        """
        prompt_config = self.get_agent_prompt_config(agent_type)
        
        try:
            formatted_prompt = prompt_config.user_prompt_template.format(**kwargs)
        except KeyError as e:
            logger.warning(f"âš ï¸ ç”¨æˆ·æç¤ºè¯æ ¼å¼åŒ–ç¼ºå°‘å‚æ•°: {e}")
            formatted_prompt = prompt_config.user_prompt_template
        
        return formatted_prompt
    
    def get_performance_config(self) -> Dict[str, Any]:
        """
        è·å–æ€§èƒ½é…ç½®
        
        Returns:
            Dict[str, Any]: æ€§èƒ½é…ç½®å­—å…¸
        """
        return self.llm_config.get('performance', {
            'concurrent_requests': 10,
            'rate_limit_per_minute': 60,
            'cache_enabled': True,
            'cache_ttl': 300
        })
    
    def get_security_config(self) -> Dict[str, Any]:
        """
        è·å–å®‰å…¨é…ç½®
        
        Returns:
            Dict[str, Any]: å®‰å…¨é…ç½®å­—å…¸
        """
        return self.llm_config.get('security', {
            'content_filter': True,
            'pii_detection': True,
            'safety_settings': {}
        })
    
    def validate_config(self) -> bool:
        """
        éªŒè¯é…ç½®çš„å®Œæ•´æ€§
        
        Returns:
            bool: é…ç½®æ˜¯å¦æœ‰æ•ˆ
        """
        try:
            # éªŒè¯ä¸»è¦é…ç½®
            primary_config = self.get_llm_config()
            if not primary_config.api_key and primary_config.api_key_env:
                if not os.getenv(primary_config.api_key_env):
                    logger.error(f"âŒ APIå¯†é’¥ç¯å¢ƒå˜é‡æœªè®¾ç½®: {primary_config.api_key_env}")
                    return False
            
            # éªŒè¯æ™ºèƒ½ä½“æç¤ºè¯é…ç½®
            required_agent_types = ['simulation_scheduler', 'satellite_agents', 'leader_agents']
            for agent_type in required_agent_types:
                prompt_config = self.get_agent_prompt_config(agent_type)
                if not prompt_config.system_prompt:
                    logger.error(f"âŒ æ™ºèƒ½ä½“ç±»å‹ {agent_type} ç¼ºå°‘ç³»ç»Ÿæç¤ºè¯")
                    return False
            
            logger.info("âœ… é…ç½®éªŒè¯é€šè¿‡")
            return True
            
        except Exception as e:
            logger.error(f"âŒ é…ç½®éªŒè¯å¤±è´¥: {e}")
            return False

    def create_litellm_client(self, agent_type: Optional[str] = None):
        """
        åˆ›å»ºLiteLLMå®¢æˆ·ç«¯

        Args:
            agent_type: æ™ºèƒ½ä½“ç±»å‹ï¼Œç”¨äºè·å–ç‰¹å®šé…ç½®

        Returns:
            LiteLLMå®¢æˆ·ç«¯å®ä¾‹
        """
        try:
            from .litellm_client import create_litellm_client

            # è·å–é…ç½®
            if agent_type:
                config = self.get_llm_config(agent_type)
            else:
                config = self.get_llm_config()

            # è½¬æ¢ä¸ºå­—å…¸æ ¼å¼
            config_dict = {
                'provider': config.provider,
                'model': config.model,
                'api_key': config.api_key,
                'api_key_env': config.api_key_env,
                'base_url': config.base_url,
                'api_version': config.api_version,
                'max_tokens': config.max_tokens,
                'temperature': config.temperature,
                'top_p': config.top_p,
                'frequency_penalty': config.frequency_penalty,
                'presence_penalty': config.presence_penalty,
                'timeout': config.timeout,
                'retry_attempts': config.retry_attempts,
                'retry_delay': config.retry_delay
            }

            logger.info(f"âœ… åˆ›å»ºLiteLLMå®¢æˆ·ç«¯: {config.model}")
            return create_litellm_client(config_dict)

        except Exception as e:
            logger.error(f"âŒ åˆ›å»ºLiteLLMå®¢æˆ·ç«¯å¤±è´¥: {e}")
            raise


# å…¨å±€é…ç½®ç®¡ç†å™¨å®ä¾‹
_llm_config_manager = None


def get_llm_config_manager(config_path: str = "config/config.yaml") -> LLMConfigManager:
    """
    è·å–å…¨å±€å¤§æ¨¡å‹é…ç½®ç®¡ç†å™¨å®ä¾‹
    
    Args:
        config_path: é…ç½®æ–‡ä»¶è·¯å¾„
        
    Returns:
        LLMConfigManager: é…ç½®ç®¡ç†å™¨å®ä¾‹
    """
    global _llm_config_manager
    if _llm_config_manager is None:
        _llm_config_manager = LLMConfigManager(config_path)
    return _llm_config_manager
