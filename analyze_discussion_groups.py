#!/usr/bin/env python3
"""
è®¨è®ºç»„ç³»ç»Ÿåˆ†æè„šæœ¬
åˆ†æå½“å‰ç³»ç»Ÿå®é™…ä½¿ç”¨çš„è®¨è®ºç»„ç±»å‹ï¼Œç¡®å®šä¿ç•™å“ªç§è®¨è®ºç»„
"""

import os
import re
import logging
from pathlib import Path
from typing import Dict, List, Set
from collections import defaultdict

# è®¾ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

class DiscussionGroupAnalyzer:
    """è®¨è®ºç»„ä½¿ç”¨æƒ…å†µåˆ†æå™¨"""
    
    def __init__(self, project_root: str):
        self.project_root = Path(project_root)
        
        # è®¨è®ºç»„ç±»å‹å’Œç›¸å…³æ–¹æ³•
        self.discussion_types = {
            'traditional': {
                'classes': ['DiscussionGroup', 'DiscussionGroupManager'],
                'methods': ['create_discussion_group', 'get_current_discussion_group'],
                'files': []
            },
            'adk_standard': {
                'classes': ['ADKStandardDiscussionSystem', 'ADKDiscussionCoordinator', 'ADKSequentialDiscussionGroup'],
                'methods': ['create_adk_standard_discussion', 'create_discussion'],
                'files': []
            },
            'adk_official': {
                'classes': ['ADKOfficialDiscussionSystem'],
                'methods': ['create_adk_official_discussion'],
                'files': []
            },
            'adk_parallel': {
                'classes': ['ADKParallelDiscussionGroupManager', 'ADKParallelDiscussionGroup'],
                'methods': ['create_discussion_group'],
                'files': []
            }
        }
        
        # ä½¿ç”¨ç»Ÿè®¡
        self.usage_stats = defaultdict(lambda: {
            'class_definitions': 0,
            'method_calls': 0,
            'imports': 0,
            'files_using': set(),
            'actual_calls': []
        })
    
    def analyze_project(self):
        """åˆ†ææ•´ä¸ªé¡¹ç›®çš„è®¨è®ºç»„ä½¿ç”¨æƒ…å†µ"""
        logger.info("ğŸ” å¼€å§‹åˆ†æé¡¹ç›®è®¨è®ºç»„ä½¿ç”¨æƒ…å†µ...")
        
        # æ‰«ææ‰€æœ‰Pythonæ–‡ä»¶
        python_files = list(self.project_root.rglob("*.py"))
        logger.info(f"ğŸ“ æ‰¾åˆ° {len(python_files)} ä¸ªPythonæ–‡ä»¶")
        
        for file_path in python_files:
            if self._should_skip_file(file_path):
                continue
            
            try:
                self._analyze_file(file_path)
            except Exception as e:
                logger.warning(f"âš ï¸ åˆ†ææ–‡ä»¶å¤±è´¥ {file_path}: {e}")
        
        # ç”Ÿæˆåˆ†ææŠ¥å‘Š
        self._generate_analysis_report()
    
    def _should_skip_file(self, file_path: Path) -> bool:
        """åˆ¤æ–­æ˜¯å¦åº”è¯¥è·³è¿‡æ–‡ä»¶"""
        skip_patterns = [
            '__pycache__',
            '.git',
            'venv',
            'env',
            '.pytest_cache',
            'node_modules'
        ]
        
        return any(pattern in str(file_path) for pattern in skip_patterns)
    
    def _analyze_file(self, file_path: Path):
        """åˆ†æå•ä¸ªæ–‡ä»¶"""
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                content = f.read()
            
            relative_path = file_path.relative_to(self.project_root)
            
            # åˆ†ææ¯ç§è®¨è®ºç»„ç±»å‹
            for discussion_type, config in self.discussion_types.items():
                self._analyze_discussion_type_in_file(
                    content, str(relative_path), discussion_type, config
                )
                
        except Exception as e:
            logger.debug(f"è¯»å–æ–‡ä»¶å¤±è´¥ {file_path}: {e}")
    
    def _analyze_discussion_type_in_file(self, content: str, file_path: str, discussion_type: str, config: Dict):
        """åˆ†ææ–‡ä»¶ä¸­ç‰¹å®šè®¨è®ºç»„ç±»å‹çš„ä½¿ç”¨"""
        stats = self.usage_stats[discussion_type]
        
        # æ£€æŸ¥ç±»å®šä¹‰
        for class_name in config['classes']:
            if re.search(rf'class\s+{class_name}\b', content):
                stats['class_definitions'] += 1
                stats['files_using'].add(file_path)
                logger.debug(f"ğŸ“ {file_path}: å®šä¹‰äº†ç±» {class_name}")
        
        # æ£€æŸ¥æ–¹æ³•è°ƒç”¨
        for method_name in config['methods']:
            # æŸ¥æ‰¾æ–¹æ³•è°ƒç”¨
            method_calls = re.findall(rf'(\w+\.)?{method_name}\s*\(', content)
            if method_calls:
                stats['method_calls'] += len(method_calls)
                stats['files_using'].add(file_path)
                stats['actual_calls'].extend([f"{file_path}:{method_name}" for _ in method_calls])
                logger.debug(f"ğŸ”§ {file_path}: è°ƒç”¨äº†æ–¹æ³• {method_name} ({len(method_calls)}æ¬¡)")
        
        # æ£€æŸ¥å¯¼å…¥
        for class_name in config['classes']:
            if re.search(rf'from\s+.*import\s+.*{class_name}', content) or \
               re.search(rf'import\s+.*{class_name}', content):
                stats['imports'] += 1
                stats['files_using'].add(file_path)
                logger.debug(f"ğŸ“¦ {file_path}: å¯¼å…¥äº† {class_name}")
    
    def _generate_analysis_report(self):
        """ç”Ÿæˆåˆ†ææŠ¥å‘Š"""
        logger.info("\n" + "="*80)
        logger.info("ğŸ“Š è®¨è®ºç»„ä½¿ç”¨æƒ…å†µåˆ†ææŠ¥å‘Š")
        logger.info("="*80)
        
        # æŒ‰ä½¿ç”¨é¢‘ç‡æ’åº
        sorted_types = sorted(
            self.usage_stats.items(),
            key=lambda x: x[1]['method_calls'] + x[1]['class_definitions'] + x[1]['imports'],
            reverse=True
        )
        
        total_usage = 0
        for discussion_type, stats in sorted_types:
            usage_score = stats['method_calls'] + stats['class_definitions'] + stats['imports']
            total_usage += usage_score
            
            logger.info(f"\nğŸ” {discussion_type.upper()} è®¨è®ºç»„:")
            logger.info(f"   ç±»å®šä¹‰: {stats['class_definitions']} ä¸ª")
            logger.info(f"   æ–¹æ³•è°ƒç”¨: {stats['method_calls']} æ¬¡")
            logger.info(f"   å¯¼å…¥è¯­å¥: {stats['imports']} æ¬¡")
            logger.info(f"   ä½¿ç”¨æ–‡ä»¶: {len(stats['files_using'])} ä¸ª")
            logger.info(f"   æ€»ä½¿ç”¨åˆ†æ•°: {usage_score}")
            
            if stats['files_using']:
                logger.info(f"   ä¸»è¦ä½¿ç”¨æ–‡ä»¶:")
                for file_path in sorted(stats['files_using'])[:5]:  # æ˜¾ç¤ºå‰5ä¸ª
                    logger.info(f"     - {file_path}")
            
            if stats['actual_calls']:
                logger.info(f"   å®é™…è°ƒç”¨ç¤ºä¾‹:")
                for call in stats['actual_calls'][:3]:  # æ˜¾ç¤ºå‰3ä¸ª
                    logger.info(f"     - {call}")
        
        # ç”Ÿæˆå»ºè®®
        logger.info("\n" + "="*80)
        logger.info("ğŸ’¡ åˆ†æç»“è®ºå’Œå»ºè®®")
        logger.info("="*80)
        
        if total_usage == 0:
            logger.info("âš ï¸ æœªæ£€æµ‹åˆ°ä»»ä½•è®¨è®ºç»„çš„ä½¿ç”¨")
            return
        
        # æ‰¾å‡ºä¸»è¦ä½¿ç”¨çš„è®¨è®ºç»„ç±»å‹
        primary_type = sorted_types[0][0] if sorted_types else None
        primary_stats = sorted_types[0][1] if sorted_types else {}
        
        if primary_type and primary_stats['method_calls'] > 0:
            logger.info(f"ğŸ¯ ä¸»è¦ä½¿ç”¨çš„è®¨è®ºç»„ç±»å‹: {primary_type.upper()}")
            logger.info(f"   ä½¿ç”¨é¢‘ç‡: {primary_stats['method_calls']} æ¬¡æ–¹æ³•è°ƒç”¨")
            logger.info(f"   æ¶‰åŠæ–‡ä»¶: {len(primary_stats['files_using'])} ä¸ª")
            
            # æ£€æŸ¥æ˜¯å¦æœ‰å…¶ä»–æ˜¾è‘—ä½¿ç”¨çš„ç±»å‹
            significant_types = [
                (t, s) for t, s in sorted_types 
                if s['method_calls'] > 0 and t != primary_type
            ]
            
            if significant_types:
                logger.info(f"\nğŸ“‹ å…¶ä»–ä½¿ç”¨çš„è®¨è®ºç»„ç±»å‹:")
                for disc_type, stats in significant_types:
                    logger.info(f"   - {disc_type}: {stats['method_calls']} æ¬¡è°ƒç”¨")
            
            # ç”Ÿæˆåˆ é™¤å»ºè®®
            logger.info(f"\nğŸ—‘ï¸ åˆ é™¤å»ºè®®:")
            unused_types = [t for t, s in sorted_types if s['method_calls'] == 0]
            if unused_types:
                logger.info(f"   å¯ä»¥å®‰å…¨åˆ é™¤çš„è®¨è®ºç»„ç±»å‹:")
                for unused_type in unused_types:
                    logger.info(f"     - {unused_type}")
            
            # ç”Ÿæˆä¿ç•™å»ºè®®
            used_types = [t for t, s in sorted_types if s['method_calls'] > 0]
            if used_types:
                logger.info(f"   å»ºè®®ä¿ç•™çš„è®¨è®ºç»„ç±»å‹:")
                for used_type in used_types:
                    stats = dict(sorted_types)[used_type]
                    logger.info(f"     - {used_type} (è°ƒç”¨ {stats['method_calls']} æ¬¡)")
        
        else:
            logger.info("âš ï¸ æœªæ£€æµ‹åˆ°æ´»è·ƒçš„è®¨è®ºç»„æ–¹æ³•è°ƒç”¨")
            logger.info("   å¯èƒ½æ‰€æœ‰è®¨è®ºç»„éƒ½æ˜¯å®šä¹‰ä½†æœªä½¿ç”¨çš„")
    
    def get_deletion_plan(self) -> Dict[str, List[str]]:
        """è·å–åˆ é™¤è®¡åˆ’"""
        deletion_plan = {
            'files_to_delete': [],
            'classes_to_remove': [],
            'methods_to_remove': [],
            'imports_to_clean': []
        }
        
        # æ‰¾å‡ºæœªä½¿ç”¨çš„è®¨è®ºç»„ç±»å‹
        for discussion_type, stats in self.usage_stats.items():
            if stats['method_calls'] == 0:  # æ²¡æœ‰å®é™…æ–¹æ³•è°ƒç”¨
                config = self.discussion_types[discussion_type]
                deletion_plan['classes_to_remove'].extend(config['classes'])
                deletion_plan['methods_to_remove'].extend(config['methods'])
        
        return deletion_plan

def main():
    """ä¸»å‡½æ•°"""
    project_root = Path(__file__).parent
    
    analyzer = DiscussionGroupAnalyzer(str(project_root))
    analyzer.analyze_project()
    
    # è·å–åˆ é™¤è®¡åˆ’
    deletion_plan = analyzer.get_deletion_plan()
    
    if deletion_plan['classes_to_remove']:
        logger.info(f"\nğŸ—‘ï¸ åˆ é™¤è®¡åˆ’:")
        logger.info(f"   å¾…åˆ é™¤çš„ç±»: {deletion_plan['classes_to_remove']}")
        logger.info(f"   å¾…åˆ é™¤çš„æ–¹æ³•: {deletion_plan['methods_to_remove']}")
    else:
        logger.info(f"\nâœ… æ‰€æœ‰è®¨è®ºç»„ç±»å‹éƒ½åœ¨ä½¿ç”¨ä¸­ï¼Œæ— éœ€åˆ é™¤")

if __name__ == "__main__":
    main()
